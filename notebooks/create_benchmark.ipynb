{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6cd1d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Tuple, List, Dict, Any, Literal, Optional\n",
    "from jaxtyping import Float\n",
    "from pathlib import Path\n",
    "from einops import rearrange, einsum, repeat\n",
    "import tqdm\n",
    "import imageio\n",
    "import shutil\n",
    "import sys\n",
    "# add \n",
    "sys.path.append(str(Path().absolute().parent))\n",
    "\n",
    "from utils.geometry_utils import CameraPose\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from einops import rearrange, repeat\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import cv2\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5966d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize data dictionary\n",
    "data_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7dedf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def compute_pose_rotation_around_x_axis(angle: float) -> Float[torch.Tensor, \"4 4\"]:\n",
    "    # input angle in degrees\n",
    "    P_rot = torch.tensor([\n",
    "        [1, 0, 0, 0],\n",
    "        [0, math.cos(angle * (math.pi / 180.0)), -math.sin(angle * (math.pi / 180.0)), 0],\n",
    "        [0, math.sin(angle * (math.pi / 180.0)), math.cos(angle * (math.pi / 180.0)), 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ], dtype=torch.float32)\n",
    "\n",
    "    return P_rot\n",
    "\n",
    "def compute_pose_rotation_around_y_axis(angle: float) -> Float[torch.Tensor, \"4 4\"]:\n",
    "    # input angle in degrees\n",
    "    P_rot = torch.tensor([\n",
    "        [math.cos(angle * (math.pi / 180.0)), 0, math.sin(angle * (math.pi / 180.0)), 0],\n",
    "        [0, 1, 0, 0],\n",
    "        [-math.sin(angle * (math.pi / 180.0)), 0, math.cos(angle * (math.pi / 180.0)), 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ], dtype=torch.float32)\n",
    "\n",
    "    return P_rot\n",
    "\n",
    "def compute_pose_rotation_around_z_axis(angle: float) -> Float[torch.Tensor, \"4 4\"]:\n",
    "    # input angle in degrees\n",
    "    P_rot = torch.tensor([\n",
    "        [math.cos(angle * (math.pi / 180.0)), -math.sin(angle * (math.pi / 180.0)), 0, 0],\n",
    "        [math.sin(angle * (math.pi / 180.0)), math.cos(angle * (math.pi / 180.0)), 0, 0],\n",
    "        [0, 0, 1, 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ], dtype=torch.float32)\n",
    "\n",
    "    return P_rot\n",
    "\n",
    "def poses4x4_to_raw(cam2world4x4: Float[torch.Tensor, \"N 4 4\"], intrinsics: Tuple[float, float, float, float]) -> Float[torch.Tensor, \"N 18\"]:\n",
    "    \"\"\"Convert 4x4 poses to raw poses.\"\"\"\n",
    "\n",
    "    world2cam = torch.linalg.inv(cam2world4x4)\n",
    "    fx, fy, cx, cy = intrinsics\n",
    "\n",
    "    intrinsics = repeat(torch.tensor([fx, fy, cx, cy, 0, 0]), 'd -> n d', n=world2cam.shape[0])\n",
    "    world2cam = world2cam[:, :3, :4].reshape(world2cam.shape[0], -1)\n",
    "    return torch.cat([intrinsics, world2cam], dim=1)\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from liegroups.numpy import SE3\n",
    "\n",
    "def smoothen_se3_trajectory(\n",
    "    poses: Float[np.ndarray, \"N 4 4\"], \n",
    "    sigma: float = 1.0,\n",
    ") -> Float[np.ndarray, \"N 4 4\"]:\n",
    "    \n",
    "    if sigma == 0:\n",
    "        return poses\n",
    "\n",
    "    # Convert raw 4x4 matrices to SE3 objects\n",
    "    se3_objs = [SE3.from_matrix(pose, normalize=True) for pose in poses]\n",
    "    \n",
    "    # Log to tangent space\n",
    "    twist_vectors = np.array([se3.log() for se3 in se3_objs])  # shape (N, 6)\n",
    "\n",
    "    # Smooth in tangent space\n",
    "    smoothed_twists = gaussian_filter1d(twist_vectors, sigma=sigma, axis=0)\n",
    "\n",
    "    # Map back to SE(3)\n",
    "    smoothed_se3s = [SE3.exp(twist) for twist in smoothed_twists]\n",
    "    smoothed_poses = np.array([se3.as_matrix() for se3 in smoothed_se3s])\n",
    "\n",
    "    return smoothed_poses\n",
    "\n",
    "def plot_camera_trajectory_topdown(poses, figsize=(10, 10)):\n",
    "    \"\"\"\n",
    "    Plot camera trajectory from a top-down view.\n",
    "    \n",
    "    Args:\n",
    "        poses: List or array of 4x4 camera pose matrices [R, T | 0, 1]\n",
    "        figsize: Figure size tuple (width, height)\n",
    "    \"\"\"\n",
    "    # Convert poses to numpy array if not already\n",
    "    poses = np.array(poses)\n",
    "    \n",
    "    # Extract camera positions (translation vectors)\n",
    "    positions = poses[:, :3, 3]\n",
    "    \n",
    "    # Create figure\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Plot trajectory\n",
    "    plt.plot(positions[:, 0], positions[:, 2], 'b-', label='Camera Path')\n",
    "    plt.scatter(positions[:, 0], positions[:, 2], c='k', s=50, label='Camera Positions')\n",
    "    \n",
    "    # Plot start and end points\n",
    "    plt.scatter(positions[0, 0], positions[0, 2], c='g', s=100, label='Start')\n",
    "    plt.scatter(positions[-1, 0], positions[-1, 2], c='y', s=100, label='End')\n",
    "    \n",
    "    # Add arrows for camera orientation (flipped 180 degrees)\n",
    "    arrow_scale = np.abs(positions).max() * 0.1\n",
    "    for pose in poses:\n",
    "        pos = pose[:3, 3]\n",
    "        # Flip the forward direction by using positive z-axis instead of negative\n",
    "        forward = pose[:3, 2]  # Camera forward direction (flipped)\n",
    "        plt.arrow(pos[0], pos[2],\n",
    "                 forward[0] * arrow_scale, forward[2] * arrow_scale,\n",
    "                 head_width=arrow_scale*0.1, head_length=arrow_scale*0.2,\n",
    "                 fc='k', ec='k', alpha=0.5)\n",
    "    \n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Z')\n",
    "    plt.title('Camera Trajectory (Top-Down View)')\n",
    "    plt.axis('equal')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    #return plt.gcf()\n",
    "\n",
    "def plot_camera_trajectory_topdown_video(poses, figsize=(5.12, 5.12), fps=10):\n",
    "    \"\"\"\n",
    "    Create a video showing the camera trajectory evolving over time from a top-down view.\n",
    "\n",
    "    Args:\n",
    "        poses: List or array of 4x4 camera pose matrices [R, T | 0, 1]\n",
    "        figsize: Figure size tuple (width, height)\n",
    "        fps: Frames per second for the output video\n",
    "    Returns:\n",
    "        List of frames as numpy arrays\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    poses = np.array(poses)\n",
    "    positions = poses[:, :3, 3]\n",
    "\n",
    "    # Calculate arrow scale based on max position values\n",
    "    arrow_scale = np.abs(positions).max() * 0.1\n",
    "\n",
    "    print(arrow_scale)\n",
    "\n",
    "    # Calculate fixed axis limits based on all positions and arrow length\n",
    "    padding_factor = 2.\n",
    "    min_padding = padding_factor * arrow_scale\n",
    "    x_min, x_max = positions[:, 0].min(), positions[:, 0].max()\n",
    "    z_min, z_max = positions[:, 2].min(), positions[:, 2].max()\n",
    "    x_padding = max((x_max - x_min) * 0.1 + padding_factor * arrow_scale, min_padding)\n",
    "    z_padding = max((z_max - z_min) * 0.1 + padding_factor * arrow_scale, min_padding)\n",
    "    x_min -= x_padding\n",
    "    x_max += x_padding\n",
    "    z_min -= z_padding\n",
    "    z_max += z_padding\n",
    "\n",
    "    frames = []\n",
    "    for t in range(len(poses)):\n",
    "        plt.figure(figsize=figsize)\n",
    "\n",
    "        # Plot trajectory up to current frame\n",
    "        plt.plot(positions[:t+1, 0], positions[:t+1, 2], 'b-', label='Camera Path')\n",
    "\n",
    "        # Plot previous camera positions in blue\n",
    "        if t > 0:\n",
    "            plt.scatter(positions[:t, 0], positions[:t, 2], c='b', s=50)\n",
    "\n",
    "        # Plot current camera position in red\n",
    "        plt.scatter(positions[t, 0], positions[t, 2], c='k', s=100, label='Current Position')\n",
    "\n",
    "        # Plot start and end points\n",
    "        plt.scatter(positions[0, 0], positions[0, 2], c='g', s=100, label='Start')\n",
    "        if t == len(poses) - 1:\n",
    "            plt.scatter(positions[-1, 0], positions[-1, 2], c='y', s=100, label='End')\n",
    "\n",
    "        # Add arrows for camera orientation up to current frame\n",
    "        for i in range(t + 1):\n",
    "            pose = poses[i]\n",
    "            pos = pose[:3, 3]\n",
    "            forward = pose[:3, 2]\n",
    "            if i == t:\n",
    "                plt.arrow(pos[0], pos[2],\n",
    "                          forward[0] * arrow_scale, forward[2] * arrow_scale,\n",
    "                          head_width=arrow_scale*0.15, head_length=arrow_scale*0.3,\n",
    "                          fc='r', ec='r', alpha=0.8, linewidth=2)\n",
    "            else:\n",
    "                plt.arrow(pos[0], pos[2],\n",
    "                          forward[0] * arrow_scale, forward[2] * arrow_scale,\n",
    "                          head_width=arrow_scale*0.1, head_length=arrow_scale*0.2,\n",
    "                          fc='k', ec='k', alpha=0.5)\n",
    "\n",
    "        plt.xlabel('X')\n",
    "        plt.ylabel('Z')\n",
    "        plt.title(f'Camera Trajectory (Top-Down View) - Frame {t+1}/{len(poses)}')\n",
    "        plt.xlim(x_min, x_max)\n",
    "        plt.ylim(z_min, z_max)\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "\n",
    "        fig = plt.gcf()\n",
    "        fig.canvas.draw()\n",
    "        frame = np.array(fig.canvas.renderer.buffer_rgba())\n",
    "        frames.append(frame)\n",
    "        plt.close()\n",
    "\n",
    "    return frames\n",
    "\n",
    "def save_frames_as_video(frames: List[np.ndarray], output_path: str, fps: int = 10):\n",
    "    \"\"\"\n",
    "    Save a list of frames as a video file.\n",
    "    \n",
    "    Args:\n",
    "        frames: List of frames as numpy arrays (RGBA format)\n",
    "        output_path: Path to save the video file\n",
    "        fps: Frames per second for the output video\n",
    "    \"\"\"\n",
    "    if not frames:\n",
    "        raise ValueError(\"No frames provided\")\n",
    "    \n",
    "    # Get frame dimensions\n",
    "    height, width = frames[0].shape[:2]\n",
    "    \n",
    "    # Create video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    # Write frames\n",
    "    for frame in frames:\n",
    "        # Convert RGBA to BGR (OpenCV format)\n",
    "        frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGBA2BGR)\n",
    "        out.write(frame_bgr)\n",
    "    \n",
    "    # Release video writer\n",
    "    out.release() \n",
    "\n",
    "def save_video_and_poses(frames, poses, intrinsics, new_folder, video_id, dummy_frame: np.ndarray = None):\n",
    "    # save the frames\n",
    "\n",
    "    os.makedirs(os.path.join(new_folder, \"test_images\", f\"{video_id}\"), exist_ok=True)\n",
    "\n",
    "    if dummy_frame is None:\n",
    "        for i, frame in enumerate(frames):\n",
    "\n",
    "            # reshape frame to 256x256\n",
    "            frame = cv2.resize(frame, (256, 256), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "            cv2.imwrite(os.path.join(new_folder, \"test_images\", f\"{video_id}\", f\"{i}.jpg\"), frame)\n",
    "    else:\n",
    "        for i in range(len(poses)):\n",
    "            frame = dummy_frame\n",
    "            frame = cv2.resize(frame, (256, 256), interpolation=cv2.INTER_LINEAR)\n",
    "            cv2.imwrite(os.path.join(new_folder, \"test_images\", f\"{video_id}\", f\"{i}.jpg\"), frame)\n",
    "    \n",
    "    # create a video from the frames with the same codec as the reference file\n",
    "    video_file = os.path.join(new_folder, \"test_256\", f\"{video_id}.mp4\")\n",
    "    \n",
    "    # Using imageio with ffmpeg backend to specify h264 codec\n",
    "    # Set bitrate similar to reference (approximately 1Mbps)\n",
    "    with imageio.get_writer(video_file, format='FFMPEG', fps=10, codec='h264', \n",
    "                          pixelformat='yuv420p', bitrate=1000000, ffmpeg_params=['-pix_fmt', 'yuv420p']) as writer:\n",
    "        if dummy_frame is None:\n",
    "            for frame in frames:\n",
    "                # reshape frame to 256x256\n",
    "                frame = cv2.resize(frame, (256, 256), interpolation=cv2.INTER_LINEAR)\n",
    "                writer.append_data(frame)\n",
    "        else:\n",
    "            for _ in range(len(poses)):\n",
    "                frame = dummy_frame\n",
    "                frame = cv2.resize(frame, (256, 256), interpolation=cv2.INTER_LINEAR)\n",
    "                writer.append_data(frame)\n",
    "\n",
    "    raw_poses = poses4x4_to_raw(poses, intrinsics)\n",
    "\n",
    "    # save the poses\n",
    "    torch.save(raw_poses, os.path.join(new_folder, \"test_poses\", f\"{video_id}.pt\"))\n",
    "\n",
    "    # copy into train_256 and train_poses\n",
    "    os.makedirs(os.path.join(new_folder, \"training_256\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(new_folder, \"training_poses\"), exist_ok=True)\n",
    "    shutil.copy(video_file, os.path.join(new_folder, \"training_256\", f\"{video_id}.mp4\"))\n",
    "    shutil.copy(os.path.join(new_folder, \"test_poses\", f\"{video_id}.pt\"), os.path.join(new_folder, \"training_poses\", f\"{video_id}.pt\"))\n",
    "\n",
    "def plot_camera_trajectory_sideview(poses, figsize=(10, 10)):\n",
    "    \"\"\"\n",
    "    Plot camera trajectory from a side view.\n",
    "    \n",
    "    Args:\n",
    "        poses: List or array of 4x4 camera pose matrices [R, T | 0, 1]\n",
    "        figsize: Figure size tuple (width, height)\n",
    "    \"\"\"\n",
    "    # Convert poses to numpy array if not already\n",
    "    poses = np.array(poses)\n",
    "    \n",
    "    # Extract camera positions (translation vectors)\n",
    "    positions = poses[:, :3, 3]\n",
    "    \n",
    "    # Create figure\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Plot trajectory (Z vs -Y for side view - flipped Y axis)\n",
    "    plt.plot(positions[:, 2], -positions[:, 1], 'b-', label='Camera Path')\n",
    "    plt.scatter(positions[:, 2], -positions[:, 1], c='k', s=50, label='Camera Positions')\n",
    "    \n",
    "    # Plot start and end points\n",
    "    plt.scatter(positions[0, 2], -positions[0, 1], c='g', s=100, label='Start')\n",
    "    plt.scatter(positions[-1, 2], -positions[-1, 1], c='y', s=100, label='End')\n",
    "    \n",
    "    # Add arrows for camera orientation\n",
    "    arrow_scale = np.abs(positions).max() * 0.1\n",
    "    for pose in poses:\n",
    "        pos = pose[:3, 3]\n",
    "        # Use camera forward direction for side view\n",
    "        forward = pose[:3, 2]  # Camera forward direction\n",
    "        plt.arrow(pos[2], -pos[1],\n",
    "                 forward[2] * arrow_scale, -forward[1] * arrow_scale,\n",
    "                 head_width=arrow_scale*0.1, head_length=arrow_scale*0.2,\n",
    "                 fc='k', ec='k', alpha=0.5)\n",
    "    \n",
    "    plt.xlabel('Z')\n",
    "    plt.ylabel('Y')\n",
    "    plt.title('Camera Trajectory (Side View)')\n",
    "    plt.axis('equal')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "def plot_camera_trajectory_sideview_video(poses, figsize=(5.12, 5.12), fps=10):\n",
    "    \"\"\"\n",
    "    Create a video showing the camera trajectory evolving over time from a side view.\n",
    "\n",
    "    Args:\n",
    "        poses: List or array of 4x4 camera pose matrices [R, T | 0, 1]\n",
    "        figsize: Figure size tuple (width, height)\n",
    "        fps: Frames per second for the output video\n",
    "    Returns:\n",
    "        List of frames as numpy arrays\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    poses = np.array(poses)\n",
    "    positions = poses[:, :3, 3]\n",
    "\n",
    "    # Calculate arrow scale based on max position values\n",
    "    arrow_scale = np.abs(positions).max() * 0.1\n",
    "\n",
    "    print(arrow_scale)\n",
    "\n",
    "    # Calculate fixed axis limits based on all positions and arrow length\n",
    "    padding_factor = 2.\n",
    "    min_padding = padding_factor * arrow_scale\n",
    "    z_min, z_max = positions[:, 2].min(), positions[:, 2].max()\n",
    "    y_min, y_max = -positions[:, 1].max(), -positions[:, 1].min()  # Flip Y limits\n",
    "    z_padding = max((z_max - z_min) * 0.1 + padding_factor * arrow_scale, min_padding)\n",
    "    y_padding = max((y_max - y_min) * 0.1 + padding_factor * arrow_scale, min_padding)\n",
    "    z_min -= z_padding\n",
    "    z_max += z_padding\n",
    "    y_min -= y_padding\n",
    "    y_max += y_padding\n",
    "\n",
    "    frames = []\n",
    "    for t in range(len(poses)):\n",
    "        plt.figure(figsize=figsize)\n",
    "\n",
    "        # Plot trajectory up to current frame (Z vs -Y for side view - flipped Y axis)\n",
    "        plt.plot(positions[:t+1, 2], -positions[:t+1, 1], 'b-', label='Camera Path')\n",
    "\n",
    "        # Plot previous camera positions in blue\n",
    "        if t > 0:\n",
    "            plt.scatter(positions[:t, 2], -positions[:t, 1], c='b', s=50)\n",
    "\n",
    "        # Plot current camera position in red\n",
    "        plt.scatter(positions[t, 2], -positions[t, 1], c='k', s=100, label='Current Position')\n",
    "\n",
    "        # Plot start and end points\n",
    "        plt.scatter(positions[0, 2], -positions[0, 1], c='g', s=100, label='Start')\n",
    "        if t == len(poses) - 1:\n",
    "            plt.scatter(positions[-1, 2], -positions[-1, 1], c='y', s=100, label='End')\n",
    "\n",
    "        # Add arrows for camera orientation up to current frame\n",
    "        for i in range(t + 1):\n",
    "            pose = poses[i]\n",
    "            pos = pose[:3, 3]\n",
    "            forward = pose[:3, 2]\n",
    "            if i == t:\n",
    "                plt.arrow(pos[2], -pos[1],\n",
    "                          forward[2] * arrow_scale, -forward[1] * arrow_scale,\n",
    "                          head_width=arrow_scale*0.15, head_length=arrow_scale*0.3,\n",
    "                          fc='r', ec='r', alpha=0.8, linewidth=2)\n",
    "            else:\n",
    "                plt.arrow(pos[2], -pos[1],\n",
    "                          forward[2] * arrow_scale, -forward[1] * arrow_scale,\n",
    "                          head_width=arrow_scale*0.1, head_length=arrow_scale*0.2,\n",
    "                          fc='k', ec='k', alpha=0.5)\n",
    "\n",
    "        plt.xlabel('Z')\n",
    "        plt.ylabel('Y')\n",
    "        plt.title(f'Camera Trajectory (Side View) - Frame {t+1}/{len(poses)}')\n",
    "        plt.xlim(z_min, z_max)\n",
    "        plt.ylim(y_min, y_max)\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "\n",
    "        fig = plt.gcf()\n",
    "        fig.canvas.draw()\n",
    "        frame = np.array(fig.canvas.renderer.buffer_rgba())\n",
    "        frames.append(frame)\n",
    "        plt.close()\n",
    "\n",
    "    return frames\n",
    "\n",
    "def plot_camera_trajectory_3dview(poses, figsize=(10, 10)):\n",
    "    \"\"\"\n",
    "    Plot camera trajectory from a 3D view (azimuth=45°, elevation=45°), with y-axis as vertical.\n",
    "\n",
    "    Args:\n",
    "        poses: List or array of 4x4 camera pose matrices [R, T | 0, 1]\n",
    "        figsize: Figure size tuple (width, height)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "    poses = np.array(poses)\n",
    "    positions = poses[:, :3, 3]\n",
    "\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # X: positions[:, 0], Y: positions[:, 2], Z: positions[:, 1] (vertical) - flipped y-axis\n",
    "    ax.plot(positions[:, 0], positions[:, 2], -positions[:, 1], 'b-', label='Camera Path')\n",
    "    ax.scatter(positions[:, 0], positions[:, 2], -positions[:, 1], c='k', s=50, label='Camera Positions')\n",
    "\n",
    "    # Start and end points\n",
    "    ax.scatter(positions[0, 0], positions[0, 2], -positions[0, 1], c='g', s=100, label='Start')\n",
    "    ax.scatter(positions[-1, 0], positions[-1, 2], -positions[-1, 1], c='y', s=100, label='End')\n",
    "\n",
    "    # Arrows for camera orientation\n",
    "    arrow_scale = np.abs(positions).max() * 0.1\n",
    "    for pose in poses:\n",
    "        pos = pose[:3, 3]\n",
    "        forward = pose[:3, 2]\n",
    "        ax.quiver(pos[0], pos[2], -pos[1],\n",
    "                  forward[0], forward[2], -forward[1],\n",
    "                  length=arrow_scale, color='k', alpha=0.5)\n",
    "\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Z')\n",
    "    ax.set_zlabel('Y (vertical)')\n",
    "    ax.set_title('Camera Trajectory (3D View, Azimuth=45°, Elevation=45°)')\n",
    "    ax.view_init(elev=45, azim=45)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_camera_trajectory_3dview_video(poses, figsize=(5.12, 5.12), fps=10):\n",
    "    \"\"\"\n",
    "    Create a video showing the camera trajectory evolving over time from a 3D view (azimuth=45°, elevation=45°), with y-axis as vertical.\n",
    "\n",
    "    Args:\n",
    "        poses: List or array of 4x4 camera pose matrices [R, T | 0, 1]\n",
    "        figsize: Figure size tuple (width, height)\n",
    "        fps: Frames per second for the output video\n",
    "    Returns:\n",
    "        List of frames as numpy arrays\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "    poses = np.array(poses)\n",
    "    positions = poses[:, :3, 3]\n",
    "\n",
    "    arrow_scale = np.abs(positions).max() * 0.1\n",
    "\n",
    "    # Axis limits with padding\n",
    "    padding = arrow_scale * 2\n",
    "    x_min, x_max = positions[:, 0].min() - padding, positions[:, 0].max() + padding\n",
    "    z_min, z_max = positions[:, 2].min() - padding, positions[:, 2].max() + padding\n",
    "    y_min, y_max = -positions[:, 1].max() - padding, -positions[:, 1].min() + padding  # Flipped y-axis limits\n",
    "\n",
    "    frames = []\n",
    "    for t in range(len(poses)):\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "        # X: positions[:, 0], Y: positions[:, 2], Z: positions[:, 1] (vertical) - flipped y-axis\n",
    "        ax.plot(positions[:t+1, 0], positions[:t+1, 2], -positions[:t+1, 1], 'b-', label='Camera Path')\n",
    "        if t > 0:\n",
    "            ax.scatter(positions[:t, 0], positions[:t, 2], -positions[:t, 1], c='b', s=50)\n",
    "        ax.scatter(positions[t, 0], positions[t, 2], -positions[t, 1], c='k', s=100, label='Current Position')\n",
    "        ax.scatter(positions[0, 0], positions[0, 2], -positions[0, 1], c='g', s=100, label='Start')\n",
    "        if t == len(poses) - 1:\n",
    "            ax.scatter(positions[-1, 0], positions[-1, 2], -positions[-1, 1], c='y', s=100, label='End')\n",
    "\n",
    "        # Arrows for camera orientation up to current frame\n",
    "        for i in range(t + 1):\n",
    "            pose = poses[i]\n",
    "            pos = pose[:3, 3]\n",
    "            forward = pose[:3, 2]\n",
    "            color = 'r' if i == t else 'k'\n",
    "            alpha = 0.8 if i == t else 0.5\n",
    "            ax.quiver(pos[0], pos[2], -pos[1],\n",
    "                      forward[0], forward[2], -forward[1],\n",
    "                      length=arrow_scale, color=color, alpha=alpha)\n",
    "\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Z')\n",
    "        ax.set_zlabel('Y (vertical)')\n",
    "        ax.set_title(f'Camera Trajectory (3D View) - Frame {t+1}/{len(poses)}')\n",
    "        ax.set_xlim(x_min, x_max)\n",
    "        ax.set_ylim(z_min, z_max)\n",
    "        ax.set_zlim(y_min, y_max)\n",
    "        ax.view_init(elev=45, azim=45)\n",
    "        ax.legend()\n",
    "\n",
    "        fig.canvas.draw()\n",
    "        frame = np.array(fig.canvas.renderer.buffer_rgba())\n",
    "        frames.append(frame)\n",
    "        plt.close()\n",
    "\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "992198a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate trajectories\n",
    "\n",
    "def generate_trajectory_panorama(\n",
    "    num_frames: int,\n",
    "    height: float,                  # y-axis coordinate of camera center\n",
    "    target_rotation_angle: float,          # target rotation angle of camera (degrees)\n",
    ") -> Float[torch.Tensor, \"N 4 4\"]: \n",
    "    \"\"\"\n",
    "    Create a cam2world trajectory depicting a panorama - a camera rotation around the y-axis (i.e. rotation in the xz plane) for \"rotation_angle\" degrees.\n",
    "    \"\"\"\n",
    "    angles = torch.linspace(0, target_rotation_angle, num_frames)       # in degrees\n",
    "    # rotation angles in radians\n",
    "    angles_rad = angles * (torch.pi / 180.0)                            # in radians\n",
    "    \n",
    "    # create cam2world matrices\n",
    "    cam2worlds = []\n",
    "    for angle in angles_rad:\n",
    "        # Create rotation matrix for x,z plane rotation\n",
    "        R_rot = torch.tensor([\n",
    "            [torch.cos(angle), 0, -torch.sin(angle)],\n",
    "            [0, 1, 0],\n",
    "            [torch.sin(angle), 0, torch.cos(angle)]\n",
    "        ], dtype=torch.float32)\n",
    "        \n",
    "        # Create new pose matrix (keep same translation)\n",
    "        cam2world = torch.eye(4, dtype=torch.float32)\n",
    "        cam2world[:3, :3] = R_rot\n",
    "        cam2world[:3, 3] = torch.tensor([0, height, 0], dtype=torch.float32)        # set y-coordinate of camera center to be designated height\n",
    "        \n",
    "        cam2worlds.append(cam2world)\n",
    "    \n",
    "    # Combine original and new poses\n",
    "    cam2worlds = torch.stack(cam2worlds)\n",
    "\n",
    "    return cam2worlds\n",
    "\n",
    "\"\"\"\n",
    "def generate_trajectory_circle(\n",
    "    num_frames: int,\n",
    "    height: float,\n",
    "    radius: float,\n",
    "    target_rotation_angle: float,\n",
    "    normalize_wrt_first_frame: bool = True,\n",
    ") -> Float[torch.Tensor, \"N 4 4\"]:\n",
    "    # Create a cam2world trajectory that traces a circle in the xz plane.\n",
    "    # The camera faces in a direction tangent to the circle.\n",
    "    \n",
    "    angles = torch.linspace(0, target_rotation_angle, num_frames)       # in degrees\n",
    "    # rotation angles in radians\n",
    "    angles_rad = angles * (torch.pi / 180.0)                            # in radians\n",
    "\n",
    "    # create cam2world matrices\n",
    "    cam2worlds = []\n",
    "    for angle in angles_rad:\n",
    "        # Create new pose matrix (keep same translation)\n",
    "        cam2world = torch.eye(4, dtype=torch.float32)\n",
    "        \n",
    "        # compute camera orientation\n",
    "        # Create rotation matrix for x,z plane rotation\n",
    "        angle += torch.pi / 2.0                             # add 90 degrees to face tangent to the circle\n",
    "        R_rot = torch.tensor([\n",
    "            [torch.cos(angle), 0, -torch.sin(angle)],\n",
    "            [0, 1, 0],\n",
    "            [torch.sin(angle), 0, torch.cos(angle)]\n",
    "        ], dtype=torch.float32)\n",
    "        cam2world[:3, :3] = R_rot\n",
    "\n",
    "        # compute camera position\n",
    "\n",
    "        cam2world[:3, 3] = torch.tensor([radius*torch.cos(angle) , height, radius*torch.sin(angle)], dtype=torch.float32)        # set y-coordinate of camera center to be designated height\n",
    "        \n",
    "        cam2worlds.append(cam2world)\n",
    "    \n",
    "    # Combine original and new poses\n",
    "    cam2worlds = torch.stack(cam2worlds)\n",
    "\n",
    "    if normalize_wrt_first_frame:\n",
    "        cam2worlds = torch.linalg.inv(cam2worlds[0:1]) @ cam2worlds\n",
    "\n",
    "    return cam2worlds\n",
    "\"\"\"\n",
    "\n",
    "def generate_trajectory_circle(\n",
    "    num_frames: int,\n",
    "    height: float,\n",
    "    radius: float,\n",
    "    target_rotation_angle: float,\n",
    "    normalize_wrt_first_frame: bool = True,\n",
    "    is_counterclockwise: bool = True,\n",
    ") -> Float[torch.Tensor, \"N 4 4\"]:\n",
    "    \"\"\"\n",
    "    Create a cam2world trajectory that traces a circle in the xz plane.\n",
    "    The camera faces in a direction tangent to the circle.\n",
    "    \n",
    "    Args:\n",
    "        num_frames: Number of frames in the trajectory\n",
    "        height: Y-coordinate of the camera center\n",
    "        radius: Radius of the circle\n",
    "        target_rotation_angle: Target rotation angle in degrees\n",
    "        normalize_wrt_first_frame: Whether to normalize poses relative to first frame\n",
    "        is_counterclockwise: If True, generate counterclockwise trajectory; if False, generate clockwise trajectory\n",
    "    \"\"\"\n",
    "    \n",
    "    angles = torch.linspace(0, target_rotation_angle, num_frames)       # in degrees\n",
    "    # rotation angles in radians\n",
    "    angles_rad = angles * (torch.pi / 180.0)                            # in radians\n",
    "\n",
    "    # create cam2world matrices\n",
    "    cam2worlds = []\n",
    "    for angle in angles_rad:\n",
    "        # Create new pose matrix (keep same translation)\n",
    "        cam2world = torch.eye(4, dtype=torch.float32)\n",
    "        \n",
    "        # compute camera position first\n",
    "        if is_counterclockwise:\n",
    "            # Counterclockwise: standard circle\n",
    "            cam2world[:3, 3] = torch.tensor([radius*torch.cos(angle), height, radius*torch.sin(angle)], dtype=torch.float32)\n",
    "            # For counterclockwise motion, tangent direction is (-sin(angle), 0, cos(angle))\n",
    "            # This is the derivative of the position with respect to angle\n",
    "            tangent_x = -torch.sin(angle)\n",
    "            tangent_z = torch.cos(angle)\n",
    "        else:\n",
    "            # Clockwise: reverse the circle direction\n",
    "            cam2world[:3, 3] = torch.tensor([radius*torch.cos(angle), height, -radius*torch.sin(angle)], dtype=torch.float32)\n",
    "            # For clockwise motion, tangent direction is (sin(angle), 0, -cos(angle))\n",
    "            # This is the negative of the counterclockwise tangent\n",
    "            tangent_x = -torch.sin(angle)\n",
    "            tangent_z = -torch.cos(angle)\n",
    "        \n",
    "        # compute camera orientation to face tangent to the trajectory\n",
    "        # Forward direction is the tangent vector\n",
    "        forward = torch.tensor([tangent_x, 0.0, tangent_z], dtype=torch.float32)\n",
    "        forward = forward / torch.norm(forward)\n",
    "        \n",
    "        # Up direction is always (0, 1, 0)\n",
    "        up = torch.tensor([0.0, 1.0, 0.0], dtype=torch.float32)\n",
    "        \n",
    "        # Right direction is up cross forward\n",
    "        right = torch.cross(up, forward)\n",
    "        right = right / torch.norm(right)\n",
    "        \n",
    "        # Recompute up to ensure orthogonality\n",
    "        up = torch.cross(forward, right)\n",
    "        \n",
    "        # Create rotation matrix\n",
    "        R = torch.stack([right, up, forward], dim=1)  # each vector is a column\n",
    "        cam2world[:3, :3] = R\n",
    "        \n",
    "        cam2worlds.append(cam2world)\n",
    "    \n",
    "    # Combine original and new poses\n",
    "    cam2worlds = torch.stack(cam2worlds)\n",
    "\n",
    "    if normalize_wrt_first_frame:\n",
    "        cam2worlds = torch.linalg.inv(cam2worlds[0:1]) @ cam2worlds\n",
    "\n",
    "    return cam2worlds\n",
    "\n",
    "def generate_trajectory_orbit(\n",
    "    num_frames: int,\n",
    "    height: float,                              # y-axis coordinate of camera center\n",
    "    start_rotation_angle: float = 0,            # start rotation angle of camera (degrees)\n",
    "    target_rotation_angle: float = 360,         # target rotation angle of camera (degrees)\n",
    "    radius: float = 0.5,                        # radius of circular orbit\n",
    "    normalize_wrt_first_frame: bool = False,\n",
    ") -> Float[torch.Tensor, \"N 4 4\"]:\n",
    "    \"\"\"\n",
    "    Create a cam2world trajectory depicting an orbital motion - camera moves in a circular path in the xz plane\n",
    "    while always looking at the center point (0,height,0).\n",
    "    \"\"\"\n",
    "    angles = torch.linspace(start_rotation_angle, target_rotation_angle, num_frames)  # in degrees\n",
    "    angles_rad = angles * (torch.pi / 180.0)                       # in radians\n",
    "    \n",
    "    # create cam2world matrices\n",
    "    cam2worlds = []\n",
    "    for angle in angles_rad:\n",
    "        # Calculate camera position on the circle\n",
    "        cam_x = radius * torch.cos(angle)\n",
    "        cam_z = radius * torch.sin(angle)\n",
    "        cam_pos = torch.tensor([cam_x, height, cam_z], dtype=torch.float32)\n",
    "        \n",
    "        # Calculate rotation matrix to look at center\n",
    "        # Forward direction = center - cam_pos (normalized)\n",
    "        forward = -cam_pos  # looking at origin\n",
    "        forward[1] = 0      # zero out y component\n",
    "        forward = forward / torch.norm(forward)\n",
    "        \n",
    "        # Right direction = up cross forward\n",
    "        up = torch.tensor([0.0, 1.0, 0.0], dtype=torch.float32)\n",
    "        right = torch.cross(up, forward)\n",
    "        right = right / torch.norm(right)\n",
    "        \n",
    "        # Recompute up to ensure orthogonality\n",
    "        up = torch.cross(forward, right)\n",
    "        \n",
    "        # Create rotation matrix\n",
    "        R = torch.stack([right, up, forward], dim=1)  # each vector is a row\n",
    "        \n",
    "        # Create full pose matrix\n",
    "        cam2world = torch.eye(4, dtype=torch.float32)\n",
    "        cam2world[:3, :3] = R\n",
    "        cam2world[:3, 3] = cam_pos\n",
    "        \n",
    "        cam2worlds.append(cam2world)\n",
    "    \n",
    "    # Combine poses\n",
    "    cam2worlds = torch.stack(cam2worlds)\n",
    "    \n",
    "    if normalize_wrt_first_frame:\n",
    "        cam2worlds = torch.linalg.solve(cam2worlds[0:1], cam2worlds)\n",
    "\n",
    "    return cam2worlds\n",
    "\n",
    "def generate_trajectory_forward_backward(\n",
    "    num_frames_forward: int,\n",
    "    height: float,\n",
    "    step_size: float,\n",
    ") -> Float[torch.Tensor, \"N 4 4\"]:\n",
    "    \"\"\"\n",
    "    Create a cam2world trajectory depicting a forward-backward motion: this means forward for \"num_frames_forward\" frames, then do a 180 -degree turn and come back to the original position .\n",
    "    \"\"\"\n",
    "    \n",
    "    cam2world = torch.eye(4, dtype=torch.float32)\n",
    "    cam2worlds = repeat(cam2world, \"i j -> t i j\", t=num_frames_forward * 2).contiguous()\n",
    "\n",
    "    # modify translation\n",
    "    translation = torch.arange(num_frames_forward) * step_size\n",
    "\n",
    "    translation = torch.cat([translation, torch.flip(translation, dims=[0])])       # translation along z-axis\n",
    "    cam2worlds[:, 2, 3] = translation\n",
    "\n",
    "    # modify rotation\n",
    "    angles_rad = torch.tensor([0] * num_frames_forward + [math.pi] * num_frames_forward)     # shape = (T,)\n",
    "    for i, angle in enumerate(angles_rad):\n",
    "        # Create rotation matrix for x,z plane rotation\n",
    "        R_rot = torch.tensor([\n",
    "            [torch.cos(angle), 0, -torch.sin(angle)],\n",
    "            [0, 1, 0],\n",
    "            [torch.sin(angle), 0, torch.cos(angle)]\n",
    "        ], dtype=torch.float32)\n",
    "        cam2worlds[i, :3, :3] = R_rot\n",
    "\n",
    "    cam2worlds[:, 1, 3] = height\n",
    "\n",
    "    return cam2worlds\n",
    "\n",
    "# function for generating straight line trajectory\n",
    "def generate_trajectory_straight_line(\n",
    "    num_frames: int,\n",
    "    step_size: float = 0.05,\n",
    "    height: float = 1.5,\n",
    ") -> Float[torch.Tensor, \"N 4 4\"]:\n",
    "    \"\"\"\n",
    "    Create a cam2world trajectory depicting a straight line along the z-axis\n",
    "    \"\"\"\n",
    "    \n",
    "    cam2worlds = repeat(torch.eye(4), \"i j -> t i j\", t=num_frames).contiguous()\n",
    "    cam2worlds[:, 2, 3] = torch.linspace(0, step_size * (num_frames - 1), num_frames)\n",
    "\n",
    "    # we want the viewing angle to the trajectory to be \"viewing_angle_rel_traj\" degrees\n",
    "    # e.g. for viewing_angle_rel_traj = -5, we want the viewing angle to be 5 degrees \"downwards\" i.e. rotation about x-axis by -5 degrees\n",
    "    #head_pose = compute_pose_rotation_around_x_axis(-viewing_angle_rel_traj)\n",
    "    #cam2worlds[:, :3, :3] = repeat(head_pose[:3, :3], \"i j -> t i j\", t=num_frames).contiguous()\n",
    "\n",
    "    return cam2worlds\n",
    "\n",
    "# function for generating indefinite staircase trajectory\n",
    "# in order for the finite-context-length diffusion model to know that the conditioning camera trajectory corresponds to a staircase, we generate trajectory comprised of alternating segments of inclined and horizontal portions.\n",
    "# this is because the conditioning camera trajectory is normalized w.r.t. first frame, and if the infinite staircase trajectory is just a straight line with the same heading angle, then for the intermediate segments the model may just as well interpret that segment as a traversal along the ground in a straight line.\n",
    "# let's start off with a straight line segment\n",
    "# then add the user-defined number of stair segments, where we define one segment as an inclined segment followed by a horizontal segment\n",
    "\n",
    "def generate_trajectory_staircase_segment(\n",
    "    num_frames_per_inclied_segment: int,\n",
    "    num_frames_per_horizontal_segment: int,\n",
    "    inclination_angle: float = 30,          # in degrees\n",
    "    step_size: float = 0.05,\n",
    "    height: float = 1.5,\n",
    ") -> Float[torch.Tensor, \"N 4 4\"]:\n",
    "    \"\"\"\n",
    "    Create a cam2world trajectory depicting a single segment of an indefinite staircase.\n",
    "    This single staircase segment is comprised of an inclined segment followed by a horizontal segment.\n",
    "    \"\"\"\n",
    "\n",
    "    # generate the inclined segment (poses relative to the first frame of the inclined segment)\n",
    "    inclined_segment = generate_trajectory_straight_line(num_frames_per_inclied_segment, step_size, height)\n",
    "    \n",
    "    # generate the horizontal segment (poses relative to the first frame of the horizontal segment)\n",
    "    horizontal_segment = generate_trajectory_straight_line(num_frames_per_horizontal_segment, step_size, height)\n",
    "    \n",
    "    # transform the horizontal segment to the coordinate frame of the first pose of the inclined segment (within this method, we'll refer to this as the \"world frame\")\n",
    "    # cam2world = last_frame_of_inclined_segment2world (<- THIS IS GIVEN BY \"inclined_segment[-1]\") @ first_frame_of_horizontal_segment2last_frame_of_inclined_segment @ cam2first_frame_of_horizontal_segment (<- THIS IS GIVEN BY \"horizontal_segment\")\n",
    "    # first_frame_of_horizontal_segment2last_frame_of_inclined_segment involves a rotation around the x-axis by inclination_angle degrees\n",
    "\n",
    "    # compute the rotation matrix for the rotation around the x-axis by inclination_angle degrees \n",
    "    # if we want to go up the stairs, we want to rotate by a negative angle\n",
    "    # if we want to go down the stairs, we want to rotate by a positive angle\n",
    "    # to make it intuitive, we'll at a negative sign in front of the inclination_angle\n",
    "    # s.t. inclination_angle = 30 degrees means we're going up the stairs\n",
    "    # and inclination_angle = -30 degrees means we're going down the stairs\n",
    "    first_frame_of_horizontal_segment2last_frame_of_inclined_segment = compute_pose_rotation_around_x_axis(-inclination_angle)\n",
    "    horizontal_segment_in_world_frame = repeat(inclined_segment[-1], 'i j -> t i j', t=num_frames_per_horizontal_segment).contiguous() @ repeat(first_frame_of_horizontal_segment2last_frame_of_inclined_segment, 'i j -> t i j', t=num_frames_per_horizontal_segment).contiguous() @ horizontal_segment\n",
    "\n",
    "    concat_traj = torch.cat([inclined_segment, horizontal_segment_in_world_frame], dim=0)\n",
    "\n",
    "    return concat_traj\n",
    "\n",
    "def generate_trajectory_staircase(\n",
    "    num_frames_start_end_straight_segment: int,\n",
    "    num_stair_segments: int,\n",
    "    num_frames_per_inclined_segment: int,\n",
    "    num_frames_per_horizontal_segment: int,\n",
    "    inclination_angle: float = 30,          # in degrees\n",
    "    step_size: float = 0.05,\n",
    "    height: float = 1.5,\n",
    "    different_viewing_angle: bool = False,\n",
    ") -> Float[torch.Tensor, \"N 4 4\"]:\n",
    "    \"\"\"\n",
    "    Create a cam2world trajectory depicting an indefinite staircase.\n",
    "    \"\"\"\n",
    "\n",
    "    segments = []\n",
    "\n",
    "    # generate the first segment at the bottom of the staircase, which is a straight line segment\n",
    "    initial_straight_segment = generate_trajectory_straight_line(num_frames_start_end_straight_segment, 2 * step_size, height)\n",
    "    segments.append(initial_straight_segment)\n",
    "\n",
    "    # generate the stair segments\n",
    "    for i in range(num_stair_segments):\n",
    "        latest_segment = segments[-1]      # shape = (T, 4, 4)\n",
    "\n",
    "        # generate the inclined segment containing camera poses relative to the first frame of the inclined segment\n",
    "        current_segment_rel_first = generate_trajectory_staircase_segment(num_frames_per_inclined_segment, num_frames_per_horizontal_segment, inclination_angle, step_size, height)\n",
    "\n",
    "        # compute the rotation matrix for the rotation around the x-axis by \"inclination_angle\" degrees\n",
    "        # if we want to go up the stairs, we want to rotate by a negative angle\n",
    "        # if we want to go down the stairs, we want to rotate by a positive angle\n",
    "        first_frame_of_current_segment2last_frame_of_previous_segment = compute_pose_rotation_around_x_axis(inclination_angle)\n",
    "    \n",
    "        current_segment_rel_world = repeat(latest_segment[-1], 'i j -> t i j', t=num_frames_per_inclined_segment + num_frames_per_horizontal_segment).contiguous() @ repeat(first_frame_of_current_segment2last_frame_of_previous_segment, 'i j -> t i j', t=num_frames_per_inclined_segment + num_frames_per_horizontal_segment).contiguous() @ current_segment_rel_first\n",
    "\n",
    "        segments.append(current_segment_rel_world)\n",
    "\n",
    "    # generate the final segment at the top of the staircase, which is a straight line segment\n",
    "    latest_segment = segments[-1]      # shape = (T, 4, 4)\n",
    "    final_straight_segment_rel_first = generate_trajectory_straight_line(num_frames_start_end_straight_segment, 2 * step_size, height)\n",
    "\n",
    "    final_straight_segment_rel_world = repeat(segments[-1][-1], 'i j -> t i j', t=num_frames_start_end_straight_segment).contiguous() @ final_straight_segment_rel_first\n",
    "\n",
    "    segments.append(final_straight_segment_rel_world)\n",
    "\n",
    "    # every odd-indexed segment is going up the stairs (minus the final segment)\n",
    "    # rotate the pose in every odd-indexed segment by -inclination_angle / 2 degrees\n",
    "    if different_viewing_angle:\n",
    "        for i in range(1, len(segments), 2):\n",
    "            segments[i][:-num_frames_per_horizontal_segment] = segments[i][:-num_frames_per_horizontal_segment] @ compute_pose_rotation_around_x_axis(-inclination_angle / 2)[None]\n",
    "\n",
    "    staircase_trajectory = torch.cat(segments, dim=0)\n",
    "\n",
    "    return staircase_trajectory\n",
    "\n",
    "def append_trajectory(cam2worlds, trajectory, traj2start_to_traj1end=None, remove_overlapping_frames=False):\n",
    "    \"\"\"\n",
    "    Append a trajectory to the end of of an existing cam2world trajectory where we assume\n",
    "    1) the existing trajectory (cam2worlds) is defined w.r.t. its first frame (i.e. the world frame)\n",
    "    2) and that the first frame of the new trajectory is related to the last frame of the existing trajectory by the user-defined transform \"traj2start_to_traj1end\"\n",
    "    \n",
    "    INPUTS:\n",
    "    cam2worlds: tensor of shape (N, 4, 4) denoting a trajectory of camera poses defined w.r.t. the first frame \"cam2worlds\"\n",
    "    trajectory: tensor of shape (M, 4, 4) denoting a trajectory of camera poses defined w.r.t. the first frame \"trajectory\"\n",
    "    traj2start_to_traj1end: tensor of shape (4, 4) denoting the transform from the last frame of \"cam2worlds\" to the first frame of \"trajectory\"\n",
    "    remove_overlapping_frames: bool denoting whether to remove overlapping frames between \"cam2worlds\" and \"trajectory\"\n",
    "\n",
    "    RETURNS:\n",
    "    cam2worlds: tensor of shape (N+M, 4, 4) denoting the concatenation of \"cam2worlds\" and \"trajectory\"\n",
    "    \"\"\"\n",
    "    device = cam2worlds.device\n",
    "    N = cam2worlds.shape[0]\n",
    "\n",
    "    if traj2start_to_traj1end is None:\n",
    "        traj2start_to_traj1end = torch.eye(4)[None].to(device)\n",
    "\n",
    "    # convert trajectory to world frame\n",
    "    trajectory_world = cam2worlds[N-1:N] @ (traj2start_to_traj1end @ trajectory)\n",
    "\n",
    "    if remove_overlapping_frames:\n",
    "        cam2worlds = cam2worlds[:-1]\n",
    "\n",
    "    return torch.cat([cam2worlds, trajectory_world], dim=0)\n",
    "\n",
    "def generate_trajectory_forward_rotate_backward(\n",
    "    num_frames_forward: int,\n",
    "    num_frames_rotate: int,\n",
    "    step_size: float,\n",
    "    height: float,\n",
    ") -> Float[torch.Tensor, \"N 4 4\"]:\n",
    "    \"\"\"\n",
    "    Generate a trajectory that goes forward, rotates, and then goes backward.\n",
    "    \"\"\"\n",
    "    # generate the forward trajectory\n",
    "    forward_segment = generate_trajectory_straight_line(num_frames_forward, step_size, height)\n",
    "    \n",
    "    # generate the rotate trajectory\n",
    "    rotate_segment = generate_trajectory_panorama(num_frames_rotate, height, 180)\n",
    "    \n",
    "    # generate the backward trajectory\n",
    "    backward_segment = generate_trajectory_straight_line(num_frames_forward, step_size, height)\n",
    "\n",
    "    cam2worlds = forward_segment\n",
    "    cam2worlds = append_trajectory(cam2worlds, rotate_segment)\n",
    "    cam2worlds = append_trajectory(cam2worlds, backward_segment)\n",
    "\n",
    "    return cam2worlds\n",
    "\n",
    "def generate_trajectory_forward_orbit_backward(\n",
    "    num_frames_forward: int,\n",
    "    num_frames_orbit: int,\n",
    "    num_frames_backward: int,\n",
    "    step_size: float,\n",
    "    height: float,\n",
    "    orbit_radius: float,\n",
    "    remove_overlapping_frames: bool = False,\n",
    ") -> Float[torch.Tensor, \"N 4 4\"]:\n",
    "    \"\"\"\n",
    "    Generate a trajectory that goes forward, orbits, and then goes backward.\n",
    "    \"\"\"\n",
    "    # generate the forward trajectory\n",
    "    forward_segment = generate_trajectory_straight_line(num_frames_forward, step_size, height)\n",
    "    \n",
    "    # generate the orbit trajectory\n",
    "    orbit_segment = generate_trajectory_orbit(num_frames_orbit, height, 180, radius=orbit_radius, normalize_wrt_first_frame=True)\n",
    "    \n",
    "    # generate the backward trajectory\n",
    "    backward_segment = generate_trajectory_straight_line(num_frames_backward, step_size, height)\n",
    "\n",
    "    cam2worlds = forward_segment\n",
    "    cam2worlds = append_trajectory(cam2worlds, orbit_segment, remove_overlapping_frames=remove_overlapping_frames)\n",
    "    cam2worlds = append_trajectory(cam2worlds, backward_segment, remove_overlapping_frames=remove_overlapping_frames)\n",
    "\n",
    "    return cam2worlds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57020d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 1-loop panorama\n",
    "num_frames = 24\n",
    "height = 1.5\n",
    "target_rotation_angle = 360 - 360 / num_frames\n",
    "\n",
    "panorama_trajectory = generate_trajectory_panorama(num_frames = num_frames, height = height, target_rotation_angle = target_rotation_angle)\n",
    "\n",
    "# visualize trajectory\n",
    "plot_camera_trajectory_topdown(panorama_trajectory)\n",
    "\n",
    "# save trajectory as a video\n",
    "frames = plot_camera_trajectory_topdown_video(panorama_trajectory)\n",
    "\n",
    "# save frames as video\n",
    "name = \"panorama_targetangle{}_{}frames_height{}\".format(str(round(target_rotation_angle, 2)).replace(\".\", \"p\"), num_frames, str(round(height, 2)).replace(\".\", \"p\"))\n",
    "save_frames_as_video(frames, \"/data/scene-rep/u/ndsong/loop-consistency/{}.mp4\".format(name))\n",
    "\n",
    "# save to data_dict\n",
    "data_dict[name] = (frames, panorama_trajectory)\n",
    "\n",
    "###########################\n",
    "\n",
    "# Take the videos and poses and save them into RE10K format\n",
    "new_folder_base = \"/data/scene-rep/u/ndsong/loop-consistency/data/\"\n",
    "new_config_dataset_base = \"/data/scene-rep/u/ndsong/loop-consistency/configurations/dataset/\"\n",
    "new_config_dataset_experiment_base = \"/data/scene-rep/u/ndsong/loop-consistency/configurations/dataset_experiment/\"\n",
    "\n",
    "# create new folder\n",
    "new_folder = new_folder_base + name\n",
    "os.makedirs(new_folder, exist_ok=True)\n",
    "\n",
    "# create subdirectories for videos and poses\n",
    "video_dirs = [\"test_256\", \"training_256\"]\n",
    "pose_dirs = [\"test_poses\", \"training_poses\"]\n",
    "\n",
    "for directory in video_dirs + pose_dirs:\n",
    "    os.makedirs(os.path.join(new_folder, directory), exist_ok=True)\n",
    "\n",
    "# create the necessary config files for each case\n",
    "# To do so, we need to copy the template config file for dataset and dataset_experiment\n",
    "# and then we need to modify the \"save_dir\" field in the dataset config file\n",
    "# 1) copy the template config file for dataset and dataset_experiment\n",
    "shutil.copy(new_config_dataset_base + \"benchmark_trajectory_template.yaml\", new_config_dataset_base + name + \".yaml\")\n",
    "shutil.copy(new_config_dataset_experiment_base + \"benchmark_trajectory_template_video_generation.yaml\", new_config_dataset_experiment_base + name + \"_video_generation.yaml\")\n",
    "\n",
    "# 2) modify the \"save_dir\" field in the dataset config file\n",
    "with open(new_config_dataset_base + name + \".yaml\", \"r\") as file:\n",
    "    dataset_config = yaml.load(file, Loader=yaml.SafeLoader)\n",
    "dataset_config[\"save_dir\"] = \"data/\" + name\n",
    "with open(new_config_dataset_base + name + \".yaml\", \"w\") as file:\n",
    "    yaml.dump(dataset_config, file)\n",
    "\n",
    "# create 100 copies of each kind of dataset with the following intrinsics\n",
    "intrinsics = [0.4969, 0.8834, 0.5000, 0.5000]\n",
    "\n",
    "for video_id in range(100):\n",
    "    \n",
    "    if name not in data_dict:\n",
    "        print(f\"Dataset {name} not found\")\n",
    "        continue\n",
    "\n",
    "    frames, poses = data_dict[name]\n",
    "    save_video_and_poses(frames, poses, intrinsics, new_folder_base + name, \"{:05d}\".format(video_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cac12d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 2-loop panorama\n",
    "num_frames = 48\n",
    "height = 1.5\n",
    "target_rotation_angle = 720 - 720 / num_frames\n",
    "\n",
    "panorama_trajectory = generate_trajectory_panorama(num_frames = num_frames, height = height, target_rotation_angle = target_rotation_angle)\n",
    "\n",
    "# visualize trajectory\n",
    "plot_camera_trajectory_topdown(panorama_trajectory)\n",
    "\n",
    "# save trajectory as a video\n",
    "frames = plot_camera_trajectory_topdown_video(panorama_trajectory)\n",
    "\n",
    "# save frames as video\n",
    "name = \"panorama_targetangle{}_{}frames_height{}\".format(str(round(target_rotation_angle, 2)).replace(\".\", \"p\"), num_frames, str(round(height, 2)).replace(\".\", \"p\"))\n",
    "save_frames_as_video(frames, \"/data/scene-rep/u/ndsong/loop-consistency/{}.mp4\".format(name))\n",
    "\n",
    "# save to data_dict\n",
    "data_dict[name] = (frames, panorama_trajectory)\n",
    "\n",
    "###########################\n",
    "\n",
    "# Take the videos and poses and save them into RE10K format\n",
    "new_folder_base = \"/data/scene-rep/u/ndsong/loop-consistency/data/\"\n",
    "new_config_dataset_base = \"/data/scene-rep/u/ndsong/loop-consistency/configurations/dataset/\"\n",
    "new_config_dataset_experiment_base = \"/data/scene-rep/u/ndsong/loop-consistency/configurations/dataset_experiment/\"\n",
    "\n",
    "# create new folder\n",
    "new_folder = new_folder_base + name\n",
    "os.makedirs(new_folder, exist_ok=True)\n",
    "\n",
    "# create subdirectories for videos and poses\n",
    "video_dirs = [\"test_256\", \"training_256\"]\n",
    "pose_dirs = [\"test_poses\", \"training_poses\"]\n",
    "\n",
    "for directory in video_dirs + pose_dirs:\n",
    "    os.makedirs(os.path.join(new_folder, directory), exist_ok=True)\n",
    "\n",
    "# create the necessary config files for each case\n",
    "# To do so, we need to copy the template config file for dataset and dataset_experiment\n",
    "# and then we need to modify the \"save_dir\" field in the dataset config file\n",
    "# 1) copy the template config file for dataset and dataset_experiment\n",
    "shutil.copy(new_config_dataset_base + \"benchmark_trajectory_template.yaml\", new_config_dataset_base + name + \".yaml\")\n",
    "shutil.copy(new_config_dataset_experiment_base + \"benchmark_trajectory_template_video_generation.yaml\", new_config_dataset_experiment_base + name + \"_video_generation.yaml\")\n",
    "\n",
    "# 2) modify the \"save_dir\" field in the dataset config file\n",
    "with open(new_config_dataset_base + name + \".yaml\", \"r\") as file:\n",
    "    dataset_config = yaml.load(file, Loader=yaml.SafeLoader)\n",
    "dataset_config[\"save_dir\"] = \"data/\" + name\n",
    "with open(new_config_dataset_base + name + \".yaml\", \"w\") as file:\n",
    "    yaml.dump(dataset_config, file)\n",
    "\n",
    "# create 100 copies of each kind of dataset with the following intrinsics\n",
    "intrinsics = [0.4969, 0.8834, 0.5000, 0.5000]\n",
    "\n",
    "for video_id in range(100):\n",
    "    \n",
    "    if name not in data_dict:\n",
    "        print(f\"Dataset {name} not found\")\n",
    "        continue\n",
    "\n",
    "    frames, poses = data_dict[name]\n",
    "    save_video_and_poses(frames, poses, intrinsics, new_folder_base + name, \"{:05d}\".format(video_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e9762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 1-loop circle\n",
    "num_frames = 24\n",
    "height = 1.5\n",
    "radius = 1.5\n",
    "target_rotation_angle = 360 - 360 / num_frames\n",
    "\n",
    "circle_trajectory = generate_trajectory_circle(num_frames = num_frames, height = height, radius = radius, target_rotation_angle = target_rotation_angle)\n",
    "\n",
    "# visualize trajectory\n",
    "plot_camera_trajectory_topdown(circle_trajectory)\n",
    "\n",
    "# save trajectory as a video\n",
    "frames = plot_camera_trajectory_topdown_video(circle_trajectory)\n",
    "\n",
    "# save frames as video\n",
    "name = \"circle_targetangle{}_{}frames_height{}_radius{}\".format(str(round(target_rotation_angle, 2)).replace(\".\", \"p\"), num_frames, str(round(height, 2)).replace(\".\", \"p\"), str(round(radius, 2)).replace(\".\", \"p\"))\n",
    "save_frames_as_video(frames, \"/data/scene-rep/u/ndsong/loop-consistency/{}.mp4\".format(name))\n",
    "\n",
    "# save to data_dict\n",
    "data_dict[name] = (frames, circle_trajectory)\n",
    "\n",
    "###########################\n",
    "\n",
    "# Take the videos and poses and save them into RE10K format\n",
    "new_folder_base = \"/data/scene-rep/u/ndsong/loop-consistency/data/\"\n",
    "new_config_dataset_base = \"/data/scene-rep/u/ndsong/loop-consistency/configurations/dataset/\"\n",
    "new_config_dataset_experiment_base = \"/data/scene-rep/u/ndsong/loop-consistency/configurations/dataset_experiment/\"\n",
    "\n",
    "# create new folder\n",
    "new_folder = new_folder_base + name\n",
    "os.makedirs(new_folder, exist_ok=True)\n",
    "\n",
    "# create subdirectories for videos and poses\n",
    "video_dirs = [\"test_256\", \"training_256\"]\n",
    "pose_dirs = [\"test_poses\", \"training_poses\"]\n",
    "\n",
    "for directory in video_dirs + pose_dirs:\n",
    "    os.makedirs(os.path.join(new_folder, directory), exist_ok=True)\n",
    "\n",
    "# create the necessary config files for each case\n",
    "# To do so, we need to copy the template config file for dataset and dataset_experiment\n",
    "# and then we need to modify the \"save_dir\" field in the dataset config file\n",
    "# 1) copy the template config file for dataset and dataset_experiment\n",
    "shutil.copy(new_config_dataset_base + \"benchmark_trajectory_template.yaml\", new_config_dataset_base + name + \".yaml\")\n",
    "shutil.copy(new_config_dataset_experiment_base + \"benchmark_trajectory_template_video_generation.yaml\", new_config_dataset_experiment_base + name + \"_video_generation.yaml\")\n",
    "\n",
    "# 2) modify the \"save_dir\" field in the dataset config file\n",
    "with open(new_config_dataset_base + name + \".yaml\", \"r\") as file:\n",
    "    dataset_config = yaml.load(file, Loader=yaml.SafeLoader)\n",
    "dataset_config[\"save_dir\"] = \"data/\" + name                             # \n",
    "with open(new_config_dataset_base + name + \".yaml\", \"w\") as file:\n",
    "    yaml.dump(dataset_config, file)\n",
    "\n",
    "# create 100 copies of each kind of dataset with the following intrinsics\n",
    "intrinsics = [0.4969, 0.8834, 0.5000, 0.5000]\n",
    "\n",
    "for video_id in range(100):\n",
    "    \n",
    "    if name not in data_dict:\n",
    "        print(f\"Dataset {name} not found\")\n",
    "        continue\n",
    "\n",
    "    frames, poses = data_dict[name]\n",
    "    save_video_and_poses(frames, poses, intrinsics, new_folder_base + name, \"{:05d}\".format(video_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733808ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 2-loop circle\n",
    "num_frames = 48\n",
    "height = 1.5\n",
    "radius = 1.5\n",
    "target_rotation_angle = 720 - 720 / num_frames\n",
    "\n",
    "circle_trajectory = generate_trajectory_circle(num_frames = num_frames, height = height, radius = radius, target_rotation_angle = target_rotation_angle)\n",
    "\n",
    "# visualize trajectory\n",
    "plot_camera_trajectory_topdown(circle_trajectory)\n",
    "\n",
    "# save trajectory as a video\n",
    "frames = plot_camera_trajectory_topdown_video(circle_trajectory)\n",
    "\n",
    "# save frames as video\n",
    "name = \"circle_targetangle{}_{}frames_height{}_radius{}\".format(str(round(target_rotation_angle, 2)).replace(\".\", \"p\"), num_frames, str(round(height, 2)).replace(\".\", \"p\"), str(round(radius, 2)).replace(\".\", \"p\"))\n",
    "save_frames_as_video(frames, \"/data/scene-rep/u/ndsong/loop-consistency/{}.mp4\".format(name))\n",
    "\n",
    "# save to data_dict\n",
    "data_dict[name] = (frames, circle_trajectory)\n",
    "\n",
    "###########################\n",
    "\n",
    "# Take the videos and poses and save them into RE10K format\n",
    "new_folder_base = \"/data/scene-rep/u/ndsong/loop-consistency/data/\"\n",
    "new_config_dataset_base = \"/data/scene-rep/u/ndsong/loop-consistency/configurations/dataset/\"\n",
    "new_config_dataset_experiment_base = \"/data/scene-rep/u/ndsong/loop-consistency/configurations/dataset_experiment/\"\n",
    "\n",
    "# create new folder\n",
    "new_folder = new_folder_base + name\n",
    "os.makedirs(new_folder, exist_ok=True)\n",
    "\n",
    "# create subdirectories for videos and poses\n",
    "video_dirs = [\"test_256\", \"training_256\"]\n",
    "pose_dirs = [\"test_poses\", \"training_poses\"]\n",
    "\n",
    "for directory in video_dirs + pose_dirs:\n",
    "    os.makedirs(os.path.join(new_folder, directory), exist_ok=True)\n",
    "\n",
    "# create the necessary config files for each case\n",
    "# To do so, we need to copy the template config file for dataset and dataset_experiment\n",
    "# and then we need to modify the \"save_dir\" field in the dataset config file\n",
    "# 1) copy the template config file for dataset and dataset_experiment\n",
    "shutil.copy(new_config_dataset_base + \"benchmark_trajectory_template.yaml\", new_config_dataset_base + name + \".yaml\")\n",
    "shutil.copy(new_config_dataset_experiment_base + \"benchmark_trajectory_template_video_generation.yaml\", new_config_dataset_experiment_base + name + \"_video_generation.yaml\")\n",
    "\n",
    "# 2) modify the \"save_dir\" field in the dataset config file\n",
    "with open(new_config_dataset_base + name + \".yaml\", \"r\") as file:\n",
    "    dataset_config = yaml.load(file, Loader=yaml.SafeLoader)\n",
    "dataset_config[\"save_dir\"] = \"data/\" + name                             # \n",
    "with open(new_config_dataset_base + name + \".yaml\", \"w\") as file:\n",
    "    yaml.dump(dataset_config, file)\n",
    "\n",
    "# create 100 copies of each kind of dataset with the following intrinsics\n",
    "intrinsics = [0.4969, 0.8834, 0.5000, 0.5000]\n",
    "\n",
    "for video_id in range(100):\n",
    "    \n",
    "    if name not in data_dict:\n",
    "        print(f\"Dataset {name} not found\")\n",
    "        continue\n",
    "\n",
    "    frames, poses = data_dict[name]\n",
    "    save_video_and_poses(frames, poses, intrinsics, new_folder_base + name, \"{:05d}\".format(video_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b114c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single up the stairs\n",
    "# parameters for staircase segment (up the stairs)\n",
    "scale_factor = 1.6\n",
    "base_step_size = 0.25\n",
    "base_circular_arc_radius = 0.5\n",
    "\n",
    "#num_frames_start_end_straight_segment = 10\n",
    "num_frames_start_end_straight_segment = 15\n",
    "num_stair_segments = 1\n",
    "step_size = base_step_size * scale_factor\n",
    "num_frames_per_inclined_segment = 16\n",
    "num_frames_per_horizontal_segment = 2\n",
    "height = 0   \n",
    "inclination_angle = 30\n",
    "viewing_angle_rel_traj = 0\n",
    "sigma = 1.0\n",
    "different_viewing_angle = True\n",
    "\n",
    "#\n",
    "up_the_stairs = generate_trajectory_staircase(num_frames_start_end_straight_segment, num_stair_segments, num_frames_per_inclined_segment, num_frames_per_horizontal_segment, inclination_angle, step_size, height, different_viewing_angle)\n",
    "\n",
    "up_the_stairs = smoothen_se3_trajectory(up_the_stairs.cpu().numpy(), sigma=sigma)\n",
    "up_the_stairs = torch.from_numpy(up_the_stairs).float()\n",
    "\n",
    "# visualize trajectory\n",
    "plot_camera_trajectory_sideview(up_the_stairs)\n",
    "\n",
    "# save trajectory as a video\n",
    "frames = plot_camera_trajectory_topdown_video(up_the_stairs)\n",
    "\n",
    "# save frames as video\n",
    "name = \"up_the_stairs_nframes{}_inclinationangle{}_stepsize{}_sigma{}_height{}_{}\".format(len(up_the_stairs), str(round(inclination_angle, 2)).replace(\".\", \"p\"), str(round(step_size, 2)).replace(\".\", \"p\"), str(round(sigma, 2)).replace(\".\", \"p\"), str(round(height, 2)).replace(\".\", \"p\"), \"differentviewingangle\" if different_viewing_angle else \"sameviewingangle\")\n",
    "save_frames_as_video(frames, \"/data/scene-rep/u/ndsong/loop-consistency/{}.mp4\".format(name))\n",
    "\n",
    "# save to data_dict\n",
    "data_dict[name] = (frames, up_the_stairs)\n",
    "\n",
    "###########################\n",
    "\n",
    "# Take the videos and poses and save them into RE10K format\n",
    "new_folder_base = \"/data/scene-rep/u/ndsong/loop-consistency/data/\"\n",
    "new_config_dataset_base = \"/data/scene-rep/u/ndsong/loop-consistency/configurations/dataset/\"\n",
    "new_config_dataset_experiment_base = \"/data/scene-rep/u/ndsong/loop-consistency/configurations/dataset_experiment/\"\n",
    "\n",
    "# create new folder\n",
    "new_folder = new_folder_base + name\n",
    "os.makedirs(new_folder, exist_ok=True)\n",
    "\n",
    "# create subdirectories for videos and poses\n",
    "video_dirs = [\"test_256\", \"training_256\"]\n",
    "pose_dirs = [\"test_poses\", \"training_poses\"]\n",
    "\n",
    "for directory in video_dirs + pose_dirs:\n",
    "    os.makedirs(os.path.join(new_folder, directory), exist_ok=True)\n",
    "\n",
    "# create the necessary config files for each case\n",
    "# To do so, we need to copy the template config file for dataset and dataset_experiment\n",
    "# and then we need to modify the \"save_dir\" field in the dataset config file\n",
    "# 1) copy the template config file for dataset and dataset_experiment\n",
    "shutil.copy(new_config_dataset_base + \"benchmark_trajectory_template.yaml\", new_config_dataset_base + name + \".yaml\")\n",
    "shutil.copy(new_config_dataset_experiment_base + \"benchmark_trajectory_template_video_generation.yaml\", new_config_dataset_experiment_base + name + \"_video_generation.yaml\")\n",
    "\n",
    "# 2) modify the \"save_dir\" field in the dataset config file\n",
    "with open(new_config_dataset_base + name + \".yaml\", \"r\") as file:\n",
    "    dataset_config = yaml.load(file, Loader=yaml.SafeLoader)\n",
    "dataset_config[\"save_dir\"] = \"data/\" + name                             # \n",
    "with open(new_config_dataset_base + name + \".yaml\", \"w\") as file:\n",
    "    yaml.dump(dataset_config, file)\n",
    "\n",
    "# create 100 copies of each kind of dataset with the following intrinsics\n",
    "intrinsics = [0.4969, 0.8834, 0.5000, 0.5000]\n",
    "\n",
    "for video_id in range(100):\n",
    "    \n",
    "    if name not in data_dict:\n",
    "        print(f\"Dataset {name} not found\")\n",
    "        continue\n",
    "\n",
    "    frames, poses = data_dict[name]\n",
    "    save_video_and_poses(frames, poses, intrinsics, new_folder_base + name, \"{:05d}\".format(video_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5506518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# staircase circuit trajectory with greater step size\n",
    "# generate 4-sided circuit with the following features:\n",
    "# 1) the first side features a trajectory going up the stairs\n",
    "# 2) the second side features a straight line trajectory\n",
    "# 3) the third side features a trajectory going down the stairs\n",
    "# 4) the fourth side features a straight line trajectory\n",
    "# consecutive sides are connected by a small circular arc of 90 degrees of a user-defined radius\n",
    "\n",
    "# parameters for staircase segment (up the stairs)\n",
    "scale_factor = 1.6\n",
    "base_step_size = 0.25\n",
    "base_circular_arc_radius = 0.5\n",
    "\n",
    "num_frames_start_end_straight_segment = 11\n",
    "num_stair_segments = 1\n",
    "step_size = base_step_size * scale_factor\n",
    "num_frames_per_inclined_segment = 11\n",
    "num_frames_per_horizontal_segment = 1\n",
    "height = 0   \n",
    "inclination_angle = 30\n",
    "viewing_angle_rel_traj = 0\n",
    "sigma = 1\n",
    "different_viewing_angle = True\n",
    "\n",
    "#\n",
    "up_the_stairs = generate_trajectory_staircase(num_frames_start_end_straight_segment, num_stair_segments, num_frames_per_inclined_segment, num_frames_per_horizontal_segment, inclination_angle, step_size, height, different_viewing_angle)\n",
    "\n",
    "up_the_stairs = smoothen_se3_trajectory(up_the_stairs.cpu().numpy(), sigma=sigma)\n",
    "up_the_stairs = torch.from_numpy(up_the_stairs).float()\n",
    "\n",
    "down_the_stairs = generate_trajectory_staircase(num_frames_start_end_straight_segment, num_stair_segments, num_frames_per_inclined_segment, num_frames_per_horizontal_segment, -inclination_angle, step_size, height, different_viewing_angle)\n",
    "\n",
    "down_the_stairs = smoothen_se3_trajectory(down_the_stairs.cpu().numpy(), sigma=sigma)\n",
    "down_the_stairs = torch.from_numpy(down_the_stairs).float()\n",
    "\n",
    "# parameters for straight line segment\n",
    "num_frames_straight_line = 12\n",
    "#\n",
    "straight_line = generate_trajectory_straight_line(num_frames=num_frames_straight_line, step_size=step_size, height=height)\n",
    "# straight line (half)\n",
    "straight_line_half = generate_trajectory_straight_line(num_frames=num_frames_straight_line//2, step_size=step_size, height=height)\n",
    "straight_line_final = generate_trajectory_straight_line(num_frames=num_frames_straight_line//2+3, step_size=step_size, height=height)\n",
    "\n",
    "# parameters for circular arc segment\n",
    "circular_arc_radius = base_circular_arc_radius * scale_factor\n",
    "num_frames_circular_arc = 7\n",
    "target_rotation_angle = 90\n",
    "circular_arc = generate_trajectory_circle(num_frames=num_frames_circular_arc, height=height, radius=circular_arc_radius, target_rotation_angle=target_rotation_angle, normalize_wrt_first_frame=True)\n",
    "\n",
    "# create a circuit comprised of the following:\n",
    "# 1) straight line (half)\n",
    "cam2worlds = straight_line_half\n",
    "\n",
    "# 2) circular arc\n",
    "#rotate_around_y_axis = compute_pose_rotation_around_y_axis(90)\n",
    "cam2worlds = append_trajectory(cam2worlds, circular_arc)\n",
    "\n",
    "# 3) up the stairs\n",
    "cam2worlds = append_trajectory(cam2worlds, up_the_stairs)\n",
    "\n",
    "# 4) circular arc\n",
    "cam2worlds = append_trajectory(cam2worlds, circular_arc)\n",
    "\n",
    "# 5) straight line\n",
    "cam2worlds = append_trajectory(cam2worlds, straight_line)\n",
    "\n",
    "# 6) circular arc\n",
    "cam2worlds = append_trajectory(cam2worlds, circular_arc)\n",
    "\n",
    "# 7) down the stairs\n",
    "cam2worlds = append_trajectory(cam2worlds, down_the_stairs)\n",
    "\n",
    "# 8) circular arc\n",
    "cam2worlds = append_trajectory(cam2worlds, circular_arc)\n",
    "\n",
    "# 9) straight line (half)\n",
    "cam2worlds = append_trajectory(cam2worlds, straight_line_half)\n",
    "\n",
    "#cam2worlds = smoothen_se3_trajectory(cam2worlds.cpu().numpy(), sigma=sigma)\n",
    "#cam2worlds = torch.from_numpy(cam2worlds)\n",
    "\n",
    "# visualize trajectory\n",
    "plot_camera_trajectory_sideview(cam2worlds)\n",
    "plot_camera_trajectory_topdown(cam2worlds)\n",
    "plot_camera_trajectory_3dview(cam2worlds)\n",
    "\n",
    "# save trajectory as a video\n",
    "step_size_str = str(round(step_size, 2)).replace(\".\", \"p\")\n",
    "frames = plot_camera_trajectory_3dview_video(cam2worlds)\n",
    "\n",
    "name = \"circuit_staircase_nframes{}_stepsize{}_incline{}_sigma{}_differentviewingangle\".format(len(cam2worlds), step_size_str, inclination_angle, sigma)\n",
    "save_frames_as_video(frames, \"/data/scene-rep/u/ndsong/loop-consistency/{}.mp4\".format(name))\n",
    "data_dict[name] = (frames, cam2worlds)\n",
    "\n",
    "###########################\n",
    "\n",
    "# Take the videos and poses and save them into RE10K format\n",
    "new_folder_base = \"/data/scene-rep/u/ndsong/loop-consistency/data/\"\n",
    "new_config_dataset_base = \"/data/scene-rep/u/ndsong/loop-consistency/configurations/dataset/\"\n",
    "new_config_dataset_experiment_base = \"/data/scene-rep/u/ndsong/loop-consistency/configurations/dataset_experiment/\"\n",
    "\n",
    "# create new folder\n",
    "new_folder = new_folder_base + name\n",
    "os.makedirs(new_folder, exist_ok=True)\n",
    "\n",
    "# create subdirectories for videos and poses\n",
    "video_dirs = [\"test_256\", \"training_256\"]\n",
    "pose_dirs = [\"test_poses\", \"training_poses\"]\n",
    "\n",
    "for directory in video_dirs + pose_dirs:\n",
    "    os.makedirs(os.path.join(new_folder, directory), exist_ok=True)\n",
    "\n",
    "# create the necessary config files for each case\n",
    "# To do so, we need to copy the template config file for dataset and dataset_experiment\n",
    "# and then we need to modify the \"save_dir\" field in the dataset config file\n",
    "# 1) copy the template config file for dataset and dataset_experiment\n",
    "shutil.copy(new_config_dataset_base + \"benchmark_trajectory_template.yaml\", new_config_dataset_base + name + \".yaml\")\n",
    "shutil.copy(new_config_dataset_experiment_base + \"benchmark_trajectory_template_video_generation.yaml\", new_config_dataset_experiment_base + name + \"_video_generation.yaml\")\n",
    "\n",
    "# 2) modify the \"save_dir\" field in the dataset config file\n",
    "with open(new_config_dataset_base + name + \".yaml\", \"r\") as file:\n",
    "    dataset_config = yaml.load(file, Loader=yaml.SafeLoader)\n",
    "dataset_config[\"save_dir\"] = \"data/\" + name                             # \n",
    "with open(new_config_dataset_base + name + \".yaml\", \"w\") as file:\n",
    "    yaml.dump(dataset_config, file)\n",
    "\n",
    "# create 100 copies of each kind of dataset with the following intrinsics\n",
    "intrinsics = [0.4969, 0.8834, 0.5000, 0.5000]\n",
    "\n",
    "for video_id in range(100):\n",
    "    \n",
    "    if name not in data_dict:\n",
    "        print(f\"Dataset {name} not found\")\n",
    "        continue\n",
    "\n",
    "    frames, poses = data_dict[name]\n",
    "    save_video_and_poses(frames, poses, intrinsics, new_folder_base + name, \"{:05d}\".format(video_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5354d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# penrose staircase trajectory with greater step size\n",
    "# generate 4-sided circuit with the following features:\n",
    "# 1) the first side features a trajectory going up the stairs\n",
    "# 2) the second side features a straight line trajectory\n",
    "# 3) the third side features a trajectory going up the stairs\n",
    "# 4) the fourth side features a straight line trajectory\n",
    "# consecutive sides are connected by a small circular arc of 90 degrees of a user-defined radius\n",
    "\n",
    "# parameters for staircase segment (up the stairs)\n",
    "scale_factor = 1.6\n",
    "base_step_size = 0.25\n",
    "base_circular_arc_radius = 0.5\n",
    "\n",
    "num_frames_start_end_straight_segment = 11\n",
    "num_stair_segments = 1\n",
    "step_size = base_step_size * scale_factor\n",
    "num_frames_per_inclined_segment = 11\n",
    "num_frames_per_horizontal_segment = 1\n",
    "height = 0   \n",
    "inclination_angle = 30\n",
    "viewing_angle_rel_traj = 0\n",
    "sigma = 1\n",
    "different_viewing_angle = True\n",
    "\n",
    "#\n",
    "up_the_stairs = generate_trajectory_staircase(num_frames_start_end_straight_segment, num_stair_segments, num_frames_per_inclined_segment, num_frames_per_horizontal_segment, inclination_angle, step_size, height, different_viewing_angle)\n",
    "\n",
    "up_the_stairs = smoothen_se3_trajectory(up_the_stairs.cpu().numpy(), sigma=sigma)\n",
    "up_the_stairs = torch.from_numpy(up_the_stairs).float()\n",
    "\n",
    "down_the_stairs = generate_trajectory_staircase(num_frames_start_end_straight_segment, num_stair_segments, num_frames_per_inclined_segment, num_frames_per_horizontal_segment, -inclination_angle, step_size, height, different_viewing_angle)\n",
    "\n",
    "down_the_stairs = smoothen_se3_trajectory(down_the_stairs.cpu().numpy(), sigma=sigma)\n",
    "down_the_stairs = torch.from_numpy(down_the_stairs).float()\n",
    "\n",
    "# parameters for straight line segment\n",
    "num_frames_straight_line = 12\n",
    "#\n",
    "straight_line = generate_trajectory_straight_line(num_frames=num_frames_straight_line, step_size=step_size, height=height)\n",
    "# straight line (half)\n",
    "straight_line_half = generate_trajectory_straight_line(num_frames=num_frames_straight_line//2, step_size=step_size, height=height)\n",
    "straight_line_final = generate_trajectory_straight_line(num_frames=num_frames_straight_line//2+3, step_size=step_size, height=height)\n",
    "\n",
    "# parameters for circular arc segment\n",
    "circular_arc_radius = base_circular_arc_radius * scale_factor\n",
    "num_frames_circular_arc = 7\n",
    "target_rotation_angle = 90\n",
    "circular_arc = generate_trajectory_circle(num_frames=num_frames_circular_arc, height=height, radius=circular_arc_radius, target_rotation_angle=target_rotation_angle, normalize_wrt_first_frame=True)\n",
    "\n",
    "# create a circuit comprised of the following:\n",
    "# 1) straight line (half)\n",
    "cam2worlds = straight_line_half\n",
    "\n",
    "# 2) circular arc\n",
    "#rotate_around_y_axis = compute_pose_rotation_around_y_axis(90)\n",
    "cam2worlds = append_trajectory(cam2worlds, circular_arc)\n",
    "\n",
    "# 3) up the stairs\n",
    "cam2worlds = append_trajectory(cam2worlds, up_the_stairs)\n",
    "\n",
    "# 4) circular arc\n",
    "cam2worlds = append_trajectory(cam2worlds, circular_arc)\n",
    "\n",
    "# 5) straight line\n",
    "cam2worlds = append_trajectory(cam2worlds, straight_line)\n",
    "\n",
    "# 6) circular arc\n",
    "cam2worlds = append_trajectory(cam2worlds, circular_arc)\n",
    "\n",
    "# 7) up the stairs\n",
    "cam2worlds = append_trajectory(cam2worlds, up_the_stairs)\n",
    "\n",
    "# 8) circular arc\n",
    "cam2worlds = append_trajectory(cam2worlds, circular_arc)\n",
    "\n",
    "# 9) straight line (half)\n",
    "cam2worlds = append_trajectory(cam2worlds, straight_line_half)\n",
    "\n",
    "#cam2worlds = smoothen_se3_trajectory(cam2worlds.cpu().numpy(), sigma=sigma)\n",
    "#cam2worlds = torch.from_numpy(cam2worlds)\n",
    "\n",
    "# visualize trajectory\n",
    "plot_camera_trajectory_sideview(cam2worlds)\n",
    "plot_camera_trajectory_topdown(cam2worlds)\n",
    "plot_camera_trajectory_3dview(cam2worlds)\n",
    "\n",
    "# save trajectory as a video\n",
    "step_size_str = str(round(step_size, 2)).replace(\".\", \"p\")\n",
    "frames = plot_camera_trajectory_3dview_video(cam2worlds)\n",
    "\n",
    "name = \"penrose_staircase_nframes{}_stepsize{}_incline{}_sigma{}_differentviewingangle\".format(len(cam2worlds), step_size_str, inclination_angle, sigma)\n",
    "save_frames_as_video(frames, \"/data/scene-rep/u/ndsong/loop-consistency/{}.mp4\".format(name))\n",
    "data_dict[name] = (frames, cam2worlds)\n",
    "\n",
    "###########################\n",
    "\n",
    "# Take the videos and poses and save them into RE10K format\n",
    "new_folder_base = \"/data/scene-rep/u/ndsong/loop-consistency/data/\"\n",
    "new_config_dataset_base = \"/data/scene-rep/u/ndsong/loop-consistency/configurations/dataset/\"\n",
    "new_config_dataset_experiment_base = \"/data/scene-rep/u/ndsong/loop-consistency/configurations/dataset_experiment/\"\n",
    "\n",
    "# create new folder\n",
    "new_folder = new_folder_base + name\n",
    "os.makedirs(new_folder, exist_ok=True)\n",
    "\n",
    "# create subdirectories for videos and poses\n",
    "video_dirs = [\"test_256\", \"training_256\"]\n",
    "pose_dirs = [\"test_poses\", \"training_poses\"]\n",
    "\n",
    "for directory in video_dirs + pose_dirs:\n",
    "    os.makedirs(os.path.join(new_folder, directory), exist_ok=True)\n",
    "\n",
    "# create the necessary config files for each case\n",
    "# To do so, we need to copy the template config file for dataset and dataset_experiment\n",
    "# and then we need to modify the \"save_dir\" field in the dataset config file\n",
    "# 1) copy the template config file for dataset and dataset_experiment\n",
    "shutil.copy(new_config_dataset_base + \"benchmark_trajectory_template.yaml\", new_config_dataset_base + name + \".yaml\")\n",
    "shutil.copy(new_config_dataset_experiment_base + \"benchmark_trajectory_template_video_generation.yaml\", new_config_dataset_experiment_base + name + \"_video_generation.yaml\")\n",
    "\n",
    "# 2) modify the \"save_dir\" field in the dataset config file\n",
    "with open(new_config_dataset_base + name + \".yaml\", \"r\") as file:\n",
    "    dataset_config = yaml.load(file, Loader=yaml.SafeLoader)\n",
    "dataset_config[\"save_dir\"] = \"data/\" + name                             # \n",
    "with open(new_config_dataset_base + name + \".yaml\", \"w\") as file:\n",
    "    yaml.dump(dataset_config, file)\n",
    "\n",
    "# create 100 copies of each kind of dataset with the following intrinsics\n",
    "intrinsics = [0.4969, 0.8834, 0.5000, 0.5000]\n",
    "\n",
    "for video_id in range(100):\n",
    "    \n",
    "    if name not in data_dict:\n",
    "        print(f\"Dataset {name} not found\")\n",
    "        continue\n",
    "\n",
    "    frames, poses = data_dict[name]\n",
    "    save_video_and_poses(frames, poses, intrinsics, new_folder_base + name, \"{:05d}\".format(video_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1e64b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# straight line\n",
    "\n",
    "num_frames = 400\n",
    "step_size = 0.05\n",
    "height = 1.5\n",
    "\n",
    "straight_line = generate_trajectory_straight_line(num_frames=num_frames, step_size=step_size, height=height)\n",
    "\n",
    "# visualize trajectory\n",
    "#plot_camera_trajectory_topdown(straight_line)\n",
    "\n",
    "# save trajectory as a video\n",
    "step_size_str = str(round(step_size, 2)).replace(\".\", \"p\")\n",
    "frames = plot_camera_trajectory_topdown_video(straight_line)\n",
    "\n",
    "name = \"straight_line_nframes{}_stepsize{}_height{}\".format(num_frames, step_size_str, height)\n",
    "save_frames_as_video(frames, \"/data/scene-rep/u/ndsong/loop-consistency/{}.mp4\".format(name))\n",
    "data_dict[name] = (frames, straight_line)\n",
    "\n",
    "###########################\n",
    "\n",
    "# Take the videos and poses and save them into RE10K format\n",
    "new_folder_base = \"/data/scene-rep/u/ndsong/loop-consistency/data/\"\n",
    "new_config_dataset_base = \"/data/scene-rep/u/ndsong/loop-consistency/configurations/dataset/\"\n",
    "new_config_dataset_experiment_base = \"/data/scene-rep/u/ndsong/loop-consistency/configurations/dataset_experiment/\"\n",
    "\n",
    "# create new folder\n",
    "new_folder = new_folder_base + name\n",
    "os.makedirs(new_folder, exist_ok=True)\n",
    "\n",
    "# create subdirectories for videos and poses\n",
    "video_dirs = [\"test_256\", \"training_256\"]\n",
    "pose_dirs = [\"test_poses\", \"training_poses\"]\n",
    "\n",
    "for directory in video_dirs + pose_dirs:\n",
    "    os.makedirs(os.path.join(new_folder, directory), exist_ok=True)\n",
    "\n",
    "# create the necessary config files for each case\n",
    "# To do so, we need to copy the template config file for dataset and dataset_experiment\n",
    "# and then we need to modify the \"save_dir\" field in the dataset config file\n",
    "# 1) copy the template config file for dataset and dataset_experiment\n",
    "shutil.copy(new_config_dataset_base + \"benchmark_trajectory_template.yaml\", new_config_dataset_base + name + \".yaml\")\n",
    "shutil.copy(new_config_dataset_experiment_base + \"benchmark_trajectory_template_video_generation.yaml\", new_config_dataset_experiment_base + name + \"_video_generation.yaml\")\n",
    "\n",
    "# 2) modify the \"save_dir\" field in the dataset config file\n",
    "with open(new_config_dataset_base + name + \".yaml\", \"r\") as file:\n",
    "    dataset_config = yaml.load(file, Loader=yaml.SafeLoader)\n",
    "dataset_config[\"save_dir\"] = \"data/\" + name                             # \n",
    "with open(new_config_dataset_base + name + \".yaml\", \"w\") as file:\n",
    "    yaml.dump(dataset_config, file)\n",
    "\n",
    "# create 100 copies of each kind of dataset with the following intrinsics\n",
    "intrinsics = [0.4969, 0.8834, 0.5000, 0.5000]\n",
    "\n",
    "for video_id in range(100):\n",
    "    \n",
    "    if name not in data_dict:\n",
    "        print(f\"Dataset {name} not found\")\n",
    "        continue\n",
    "\n",
    "    frames, poses = data_dict[name]\n",
    "    save_video_and_poses(frames, poses, intrinsics, new_folder_base + name, \"{:05d}\".format(video_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf78a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ever-ascending staircase trajectory with greater step size\n",
    "# generate 4-sided circuit with the following features:\n",
    "# 1) the first side features a trajectory going up the stairs\n",
    "# 2) the second side features a straight line trajectory\n",
    "# 3) the third side features a trajectory going up the stairs\n",
    "# 4) the fourth side features a straight line trajectory\n",
    "# consecutive sides are connected by a small circular arc of 90 degrees of a user-defined radius\n",
    "\n",
    "num_staircase_loops = 90\n",
    "\n",
    "# parameters for staircase segment (up the stairs)\n",
    "scale_factor = 1.6\n",
    "base_step_size = 0.25\n",
    "base_circular_arc_radius = 0.5\n",
    "\n",
    "num_frames_start_end_straight_segment = 11\n",
    "num_stair_segments = 1\n",
    "step_size = base_step_size * scale_factor\n",
    "num_frames_per_inclined_segment = 11\n",
    "num_frames_per_horizontal_segment = 1\n",
    "height = 0   \n",
    "inclination_angle = 30\n",
    "viewing_angle_rel_traj = 0\n",
    "sigma = 1\n",
    "different_viewing_angle = True\n",
    "\n",
    "#\n",
    "up_the_stairs = generate_trajectory_staircase(num_frames_start_end_straight_segment, num_stair_segments, num_frames_per_inclined_segment, num_frames_per_horizontal_segment, inclination_angle, step_size, height, different_viewing_angle)\n",
    "\n",
    "up_the_stairs = smoothen_se3_trajectory(up_the_stairs.cpu().numpy(), sigma=sigma)\n",
    "up_the_stairs = torch.from_numpy(up_the_stairs).float()\n",
    "\n",
    "down_the_stairs = generate_trajectory_staircase(num_frames_start_end_straight_segment, num_stair_segments, num_frames_per_inclined_segment, num_frames_per_horizontal_segment, -inclination_angle, step_size, height, different_viewing_angle)\n",
    "\n",
    "down_the_stairs = smoothen_se3_trajectory(down_the_stairs.cpu().numpy(), sigma=sigma)\n",
    "down_the_stairs = torch.from_numpy(down_the_stairs).float()\n",
    "\n",
    "# parameters for straight line segment\n",
    "num_frames_straight_line = 12\n",
    "#\n",
    "straight_line = generate_trajectory_straight_line(num_frames=num_frames_straight_line, step_size=step_size, height=height)\n",
    "# straight line (half)\n",
    "straight_line_half = generate_trajectory_straight_line(num_frames=num_frames_straight_line//2, step_size=step_size, height=height)\n",
    "straight_line_final = generate_trajectory_straight_line(num_frames=num_frames_straight_line//2+3, step_size=step_size, height=height)\n",
    "\n",
    "# parameters for circular arc segment\n",
    "circular_arc_radius = base_circular_arc_radius * scale_factor\n",
    "num_frames_circular_arc = 7\n",
    "target_rotation_angle = 90\n",
    "circular_arc = generate_trajectory_circle(num_frames=num_frames_circular_arc, height=height, radius=circular_arc_radius, target_rotation_angle=target_rotation_angle, normalize_wrt_first_frame=True)\n",
    "\n",
    "# create a circuit comprised of the following:\n",
    "# 1) straight line (half)\n",
    "cam2worlds = straight_line_half\n",
    "\n",
    "for i in range(num_staircase_loops):\n",
    "    # 2) circular arc\n",
    "    #rotate_around_y_axis = compute_pose_rotation_around_y_axis(90)\n",
    "    cam2worlds = append_trajectory(cam2worlds, circular_arc)\n",
    "\n",
    "    # 3) up the stairs\n",
    "    cam2worlds = append_trajectory(cam2worlds, up_the_stairs)\n",
    "\n",
    "    # 4) circular arc\n",
    "    cam2worlds = append_trajectory(cam2worlds, circular_arc)\n",
    "\n",
    "    # 5) straight line\n",
    "    cam2worlds = append_trajectory(cam2worlds, straight_line)\n",
    "\n",
    "    # 6) circular arc\n",
    "    cam2worlds = append_trajectory(cam2worlds, circular_arc)\n",
    "\n",
    "    # 7) up the stairs\n",
    "    cam2worlds = append_trajectory(cam2worlds, up_the_stairs)\n",
    "\n",
    "    # 8) circular arc\n",
    "    cam2worlds = append_trajectory(cam2worlds, circular_arc)\n",
    "\n",
    "    if i < num_staircase_loops - 1:\n",
    "        # 9) staright line (full)\n",
    "        cam2worlds = append_trajectory(cam2worlds, straight_line)\n",
    "    else:\n",
    "        # 10) staright line (half)\n",
    "        cam2worlds = append_trajectory(cam2worlds, straight_line_half)\n",
    "\n",
    "#cam2worlds = smoothen_se3_trajectory(cam2worlds.cpu().numpy(), sigma=sigma)\n",
    "#cam2worlds = torch.from_numpy(cam2worlds)\n",
    "\n",
    "# visualize trajectory\n",
    "#plot_camera_trajectory_sideview(cam2worlds)\n",
    "#plot_camera_trajectory_topdown(cam2worlds)\n",
    "#plot_camera_trajectory_3dview(cam2worlds)\n",
    "\n",
    "# save trajectory as a video\n",
    "step_size_str = str(round(step_size, 2)).replace(\".\", \"p\")\n",
    "#frames = plot_camera_trajectory_3dview_video(cam2worlds)\n",
    "# because this is such a long video, we will create a dummy frame\n",
    "dummy_frame = np.zeros((256, 256, 4), dtype=np.uint8)\n",
    "dummy_frame[:, :, -1] = 255\n",
    "\n",
    "name = f\"infinite_staircase_nframes{len(cam2worlds)}_nloops{num_staircase_loops}_stepsize{step_size_str}_incline{inclination_angle}_sigma{sigma}_differentviewingangle\"\n",
    "#save_frames_as_video(frames, \"/data/scene-rep/u/ndsong/loop-consistency/{}.mp4\".format(name))\n",
    "data_dict[name] = (frames, cam2worlds)\n",
    "print(\"saved to data_dict\")\n",
    "\n",
    "###########################\n",
    "\n",
    "# Take the videos and poses and save them into RE10K format\n",
    "new_folder_base = \"/data/scene-rep/u/ndsong/loop-consistency/data/\"\n",
    "new_config_dataset_base = \"/data/scene-rep/u/ndsong/loop-consistency/configurations/dataset/\"\n",
    "new_config_dataset_experiment_base = \"/data/scene-rep/u/ndsong/loop-consistency/configurations/dataset_experiment/\"\n",
    "\n",
    "# create new folder\n",
    "new_folder = new_folder_base + name\n",
    "os.makedirs(new_folder, exist_ok=True)\n",
    "\n",
    "# create subdirectories for videos and poses\n",
    "video_dirs = [\"test_256\", \"training_256\"]\n",
    "pose_dirs = [\"test_poses\", \"training_poses\"]\n",
    "\n",
    "for directory in video_dirs + pose_dirs:\n",
    "    os.makedirs(os.path.join(new_folder, directory), exist_ok=True)\n",
    "\n",
    "# create the necessary config files for each case\n",
    "# To do so, we need to copy the template config file for dataset and dataset_experiment\n",
    "# and then we need to modify the \"save_dir\" field in the dataset config file\n",
    "# 1) copy the template config file for dataset and dataset_experiment\n",
    "shutil.copy(new_config_dataset_base + \"benchmark_trajectory_template.yaml\", new_config_dataset_base + name + \".yaml\")\n",
    "shutil.copy(new_config_dataset_experiment_base + \"benchmark_trajectory_template_video_generation.yaml\", new_config_dataset_experiment_base + name + \"_video_generation.yaml\")\n",
    "print(\"copied config files\")\n",
    "\n",
    "# 2) modify the \"save_dir\" field in the dataset config file\n",
    "with open(new_config_dataset_base + name + \".yaml\", \"r\") as file:\n",
    "    dataset_config = yaml.load(file, Loader=yaml.SafeLoader)\n",
    "dataset_config[\"save_dir\"] = \"data/\" + name                             # \n",
    "with open(new_config_dataset_base + name + \".yaml\", \"w\") as file:\n",
    "    yaml.dump(dataset_config, file)\n",
    "print(\"modified save_dir in dataset config file\")\n",
    "# create 100 copies of each kind of dataset with the following intrinsics\n",
    "intrinsics = [0.4969, 0.8834, 0.5000, 0.5000]\n",
    "\n",
    "#for video_id in range(100):\n",
    "for video_id in range(1):\n",
    "    \n",
    "    if name not in data_dict:\n",
    "        print(f\"Dataset {name} not found\")\n",
    "        continue\n",
    "\n",
    "    frames, poses = data_dict[name]\n",
    "    #save_video_and_poses(frames, poses, intrinsics, new_folder_base + name, \"{:05d}\".format(video_id))\n",
    "    save_video_and_poses(frames, poses, intrinsics, new_folder_base + name, \"{:05d}\".format(video_id), dummy_frame=dummy_frame)\n",
    "\n",
    "print(\"created dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204a8f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2529159/3969095055.py:190: UserWarning: Using torch.cross without specifying the dim arg is deprecated.\n",
      "Please either pass the dim explicitly or simply use torch.linalg.cross.\n",
      "The default value of dim will change to agree with that of linalg.cross in a future release. (Triggered internally at /pytorch/aten/src/ATen/native/Cross.cpp:63.)\n",
      "  right = torch.cross(up, forward)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15000000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n",
      "Multiple -pix_fmt options specified for stream 0, only the last option '-pix_fmt yuv420p' will be used.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# forward orbit backward trajectory within a loop closing window\n",
    "num_frames_forward=9\n",
    "num_frames_orbit=6\n",
    "num_frames_backward=11\n",
    "step_size=0.15\n",
    "height=1.5\n",
    "orbit_radius=0.15\n",
    "remove_overlapping_frames=True\n",
    "\n",
    "forward_orbit_backward = generate_trajectory_forward_orbit_backward(num_frames_forward=num_frames_forward, num_frames_orbit=num_frames_orbit, num_frames_backward=num_frames_backward, step_size=step_size, height=height, orbit_radius=orbit_radius, remove_overlapping_frames=remove_overlapping_frames)\n",
    "\n",
    "# visualize trajectory\n",
    "plot_camera_trajectory_sideview(forward_orbit_backward)\n",
    "\n",
    "# save trajectory as a video\n",
    "frames = plot_camera_trajectory_topdown_video(forward_orbit_backward)\n",
    "\n",
    "# save frames as video\n",
    "name = \"forward_orbit_backward_loop_closing_window\"\n",
    "save_frames_as_video(frames, \"/data/scene-rep/u/ndsong/loop-consistency/{}.mp4\".format(name))\n",
    "\n",
    "# sample frames\n",
    "sampled_indices = [18,19,4,5,6,7,16,17]\n",
    "\n",
    "# save to data_dict\n",
    "data_dict[name] = ([frames[i] for i in sampled_indices], forward_orbit_backward[sampled_indices])\n",
    "\n",
    "###########################\n",
    "\n",
    "# Take the videos and poses and save them into RE10K format\n",
    "new_folder_base = \"/data/scene-rep/u/ndsong/loop-consistency/data/\"\n",
    "new_config_dataset_base = \"/data/scene-rep/u/ndsong/loop-consistency/configurations/dataset/\"\n",
    "new_config_dataset_experiment_base = \"/data/scene-rep/u/ndsong/loop-consistency/configurations/dataset_experiment/\"\n",
    "\n",
    "# create new folder\n",
    "new_folder = new_folder_base + name\n",
    "os.makedirs(new_folder, exist_ok=True)\n",
    "\n",
    "# create subdirectories for videos and poses\n",
    "video_dirs = [\"test_256\", \"training_256\"]\n",
    "pose_dirs = [\"test_poses\", \"training_poses\"]\n",
    "\n",
    "for directory in video_dirs + pose_dirs:\n",
    "    os.makedirs(os.path.join(new_folder, directory), exist_ok=True)\n",
    "\n",
    "# create the necessary config files for each case\n",
    "# To do so, we need to copy the template config file for dataset and dataset_experiment\n",
    "# and then we need to modify the \"save_dir\" field in the dataset config file\n",
    "# 1) copy the template config file for dataset and dataset_experiment\n",
    "shutil.copy(new_config_dataset_base + \"benchmark_trajectory_template.yaml\", new_config_dataset_base + name + \".yaml\")\n",
    "shutil.copy(new_config_dataset_experiment_base + \"benchmark_trajectory_template_video_generation.yaml\", new_config_dataset_experiment_base + name + \"_video_generation.yaml\")\n",
    "\n",
    "# 2) modify the \"save_dir\" field in the dataset config file\n",
    "with open(new_config_dataset_base + name + \".yaml\", \"r\") as file:\n",
    "    dataset_config = yaml.load(file, Loader=yaml.SafeLoader)\n",
    "dataset_config[\"save_dir\"] = \"data/\" + name                             # \n",
    "with open(new_config_dataset_base + name + \".yaml\", \"w\") as file:\n",
    "    yaml.dump(dataset_config, file)\n",
    "\n",
    "# create 100 copies of each kind of dataset with the following intrinsics\n",
    "intrinsics = [0.4969, 0.8834, 0.5000, 0.5000]\n",
    "\n",
    "for video_id in range(100):\n",
    "    \n",
    "    if name not in data_dict:\n",
    "        print(f\"Dataset {name} not found\")\n",
    "        continue\n",
    "\n",
    "    frames, poses = data_dict[name]\n",
    "    save_video_and_poses(frames, poses, intrinsics, new_folder_base + name, \"{:05d}\".format(video_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b70077",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dfot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
